<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Study Julia with me | vladium</title>
    <link>/tutorials/study_julia_with_me/</link>
      <atom:link href="/tutorials/study_julia_with_me/index.xml" rel="self" type="application/rss+xml" />
    <description>Study Julia with me</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© vladium 2019</copyright><lastBuildDate>Sat, 21 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Study Julia with me</title>
      <link>/tutorials/study_julia_with_me/</link>
    </image>
    
    <item>
      <title></title>
      <link>/tutorials/study_julia_with_me/structure/</link>
      <pubDate>Mon, 23 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/tutorials/study_julia_with_me/structure/</guid>
      <description>

&lt;h2 id=&#34;suggested-software-setup&#34;&gt;Suggested software setup&lt;/h2&gt;

&lt;p&gt;I have been using Julia successfully on MacOS and Linux (Fedora). I would suggest starting with a &lt;a href=&#34;https://juliacomputing.com/products/juliapro&#34; target=&#34;_blank&#34;&gt;JuliaPro installer&lt;/a&gt; for this study. I&amp;rsquo;ve kept a few notes about my install process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;I&amp;rsquo;ve been using &lt;a href=&#34;https://pkg.juliacomputing.com/juliapro/1201/JuliaPro-1.2.0-1_build-51.sh&#34; target=&#34;_blank&#34;&gt;v1.2&lt;/a&gt; so far, both REPL and Juno &amp;ldquo;IDE&amp;rdquo;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;on MacOS you will need to have XCode tools installed, see the &lt;a href=&#34;https://juliacomputing.com/docs/JuliaProQuickStartGuideMac_1.2.0-1.pdf&#34; target=&#34;_blank&#34;&gt;install guide&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;on Linux the &lt;a href=&#34;https://juliacomputing.com/docs/JuliaProQuickStartGuideLinux_1.2.0-1.pdf&#34; target=&#34;_blank&#34;&gt;install guide&lt;/a&gt; mentions needing these libs (install via yum/dnf/apt-get/etc, I only needed to add xclip):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;xclip
libXScrnSaver
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;apparently, starting with v1.2 what&amp;rsquo;s included appears to have changed: to minimize the installer size the &amp;ldquo;curated list of packages&amp;rdquo; are no longer part of the download itself. They can be installed via the usual &lt;code&gt;Pgk&lt;/code&gt; commands. What&amp;rsquo;s different for &amp;ldquo;curated&amp;rdquo; packages is that the install will be configured to use Julia Computing&amp;rsquo;s github repo&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:Julia-packages-a&#34;&gt;&lt;a href=&#34;#fn:Julia-packages-a&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; so that only the supposedly tested versions are available. Using Julia Computing&amp;rsquo;s repo will require authenticating to get their token. Keep this in mind if you plan to play with packages outside of their supported list.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;for REPL you can use Juno&amp;rsquo;s &amp;ldquo;REPL&amp;rdquo; tab. I find that doing so gives me experince similar to that of RStudio (a good thing):&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;juno_begin.png&#34; alt=&#34;&#34; /&gt;{ width=80% }&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;if you prefer not to rely on the IDE (which is not that great right now) and use REPL (which is very functional), you can use &lt;code&gt;julia&lt;/code&gt; binary from your JuliaPro distribution:

&lt;ul&gt;
&lt;li&gt;MacOS: &lt;code&gt;/Applications/JuliaPro-&amp;lt;version&amp;gt;.app/Contents/Resources/julia/Contents/Resources/julia/bin/julia&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Linux: &lt;code&gt;&amp;lt;install dir&amp;gt;/Julia/bin/julia&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;faqs-and-tips-for-fellow-julia-explorers&#34;&gt;FAQs and tips for fellow Julia explorers&lt;/h2&gt;

&lt;h3 id=&#34;general&#34;&gt;General&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;if you&amp;rsquo;re working with custom types, it is recommended to keep work code in a module (which could be as simple as keeping it inside a &lt;code&gt;module MyModule ... end&lt;/code&gt; block) even for one-off stuff: onlike, say, R or Python Julia currently &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/faq/#How-can-I-modify-the-declaration-of-a-type-in-my-session?-1&#34; target=&#34;_blank&#34;&gt;does not allow updating type definitions within a session without restarting it&lt;/a&gt;. It seems to have gone through several iterations of addressing this workflow need, but right now re-&lt;code&gt;include()&lt;/code&gt;ing a module seems to be what&amp;rsquo;s guaranteed to work.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;there is also &lt;a href=&#34;https://github.com/timholy/Revise.jl&#34; target=&#34;_blank&#34;&gt;Revise.jl&lt;/a&gt; (which I haven&amp;rsquo;t tried yet)&lt;/li&gt;
&lt;li&gt;see &lt;a href=&#34;https://discourse.julialang.org/t/removal-of-workspace-and-a-way-to-clear-variables/11107/8&#34; target=&#34;_blank&#34;&gt;this discussion&lt;/a&gt; for more color&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;another reason for working inside a module is because code will run faster (it will be JIT&amp;rsquo;ed sooner)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;juno&#34;&gt;Juno&lt;/h3&gt;

&lt;p&gt;Juno is basically a few packages inside &lt;a href=&#34;https://atom.io&#34; target=&#34;_blank&#34;&gt;Atom&lt;/a&gt;. It is not quite an &amp;ldquo;IDE&amp;rdquo; at this point. &lt;a href=&#34;https://code.visualstudio.com/&#34; target=&#34;_blank&#34;&gt;Visual Studio Code&lt;/a&gt; might be a reasonable alternative, but in my experiments VSC had trouble with Julia v1.2. Juno comes bundled with a &lt;code&gt;julia&lt;/code&gt; build from the same entity.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;as a result of being a collection of Atom packages, some things you might want to tweak in the UI could be dispersed over multiple places. For example:

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Julia Client&amp;rdquo; package:

&lt;ul&gt;
&lt;li&gt;you may wish to choose positioning of various tabs: Workspace, Documentation, Plots, REPL, etc&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;tool-bar&amp;rdquo; package:

&lt;ul&gt;
&lt;li&gt;you might want to opt for smaller icons&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;tree-view&amp;rdquo; package:

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Always Open Existing&amp;rdquo;, &amp;ldquo;Auto Reveal&amp;rdquo; settings might be of interest&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;books-other-resources&#34;&gt;Books, other resources&lt;/h2&gt;

&lt;p&gt;There is a constantly growing list of resources at &lt;a href=&#34;https://julialang.org/learning/&#34; target=&#34;_blank&#34;&gt;https://julialang.org&lt;/a&gt;. I list below some resources that I&amp;rsquo;ve either used myself or that seemed to stand out from the rest.&lt;/p&gt;

&lt;h4 id=&#34;books-about-or-based-on-julia-v1-0&#34;&gt;books about or based on Julia v1.0+:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://benlauwens.github.io/ThinkJulia.jl/latest/book.html&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Think Julia: How to Think Like a Computer Scientist&amp;rdquo;&lt;/a&gt; by Ben Lauwens and Allen Downey.

&lt;ul&gt;
&lt;li&gt;this is the only &amp;ldquo;pure computer science&amp;rdquo; Julia book in my list.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ucidatascienceinitiative.github.io/IntroToJulia/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;A Deep Introduction to Julia for Data Science and Scientific Computing&amp;rdquo;&lt;/a&gt; by Chris Rackauckas.

&lt;ul&gt;
&lt;li&gt;the author is very active in Julia space; this material seems very good (if you&amp;rsquo;re ok with notebooks).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/h-Klok/StatsWithJuliaBook&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Statistics with Julia: Fundamentals for Data Science, Machine Learning and Artificial Intelligence&amp;rdquo;&lt;/a&gt; by Hayden Klok and Yoni Nazarathy (&lt;a href=&#34;https://web.archive.org/web/20190902200758/https://people.smp.uq.edu.au/YoniNazarathy/julia-stats/StatisticsWithJulia.pdf&#34; target=&#34;_blank&#34;&gt;2019 draft PDF free from the authors&lt;/a&gt;).

&lt;ul&gt;
&lt;li&gt;based on a statistics course at the University of Queensland; Julia crash course in Chapter 1 and a handy &amp;ldquo;How-to&amp;rdquo; in Appendix A.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.chkwon.net/julia/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Julia Programming for Operations Research, 2nd ed.&amp;rdquo;&lt;/a&gt; by Changhyun Kwon.

&lt;ul&gt;
&lt;li&gt;another Julia crash course chapter; JuMP workship.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;reference-docs&#34;&gt;reference docs:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.julialang.org/en/v1/&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Julia 1.2 Documentation&amp;rdquo;&lt;/a&gt;, HTML and PDF.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikibooks.org/wiki/Introducing_Julia&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Introducing Julia&amp;rdquo;&lt;/a&gt; Wikibook, a nice complement to the language manual.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;video-lectures-talks&#34;&gt;video lectures, talks:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/8h8rQyEpiZA&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;Intro to Julia 1.0&amp;rdquo;&lt;/a&gt; by Jane Herriman of Julia Computing.&lt;/li&gt;
&lt;li&gt;Videos from &lt;a href=&#34;https://www.youtube.com/user/JuliaLanguage/videos?view=0&amp;amp;sort=dd&amp;amp;flow=grid&#34; target=&#34;_blank&#34;&gt;JuliaCon 2019&lt;/a&gt; &amp;ndash; some good stuff, particularly by Julia creators.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;online-practice&#34;&gt;online practice:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.juliabox.com&#34; target=&#34;_blank&#34;&gt;Julia Box&lt;/a&gt; from Julia Computing has a free plan.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://exercism.io/tracks/julia&#34; target=&#34;_blank&#34;&gt;Julia exercism track&lt;/a&gt; looks like a good &lt;a href=&#34;https://exercism.io/tracks/julia/exercises&#34; target=&#34;_blank&#34;&gt;collection of exercises&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:Julia-packages-a&#34;&gt;Julia packages are maintained as git repos. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:Julia-packages-a&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How do you say &#34;0/1 knapsack&#34; in four languages?</title>
      <link>/tutorials/study_julia_with_me/knapsack_benchmark/</link>
      <pubDate>Wed, 02 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/tutorials/study_julia_with_me/knapsack_benchmark/</guid>
      <description>


&lt;p&gt;Every once in a while, you need to try an algorithm that’s “custom enough” that it must be coded directly in your “research language”. Perhaps the existing “high-performance” libs don’t support your desired variant or it’s too much setup work switching to another language just to prototype a quick one-off idea. This an instance of the &lt;a href=&#34;https://www.nature.com/articles/d41586-019-02310-3&#34;&gt;“two language problem”&lt;/a&gt; that’s been the reality of technical computing for decades.&lt;/p&gt;
&lt;p&gt;Users of R, Python, and similar “high-productivity” environments know that native control flow constructs (for-loops, etc) in those languages kill performance unless they can be expressed in “vectorized” form. One big attraction of Julia to me is that it claims to fix this inconvenience. Let’s have a look.&lt;/p&gt;
&lt;div id=&#34;preview&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Preview&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Julia, Python, Java, and C++ are compared for implementing the same iterative algorithm (knapsack solver).&lt;/li&gt;
&lt;li&gt;The implementation does virtually no memory allocation, so what’s being tested is the speed of looping and array access.&lt;/li&gt;
&lt;li&gt;Julia is &lt;em&gt;fast&lt;/em&gt; (although not quite as fast as C++ or Java). Python, however, comes out looking &lt;em&gt;horribly slow&lt;/em&gt; by comparison.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;benchmark-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Benchmark problem&lt;/h2&gt;
&lt;p&gt;For a simple yet realistic test of performance let’s code a solution to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Knapsack_problem#0/1_knapsack_problem&#34;&gt;0/1 knapsack&lt;/a&gt; problem. I am sure you’ve heard of it – it is a classic discrete optimization problem in its own right and shows up as a &lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_knapsack_problems&#34;&gt;building block&lt;/a&gt; within many optimization algorithms.&lt;/p&gt;
&lt;p&gt;As a reminder, the problem is to pack a knapsack of finite weight capacity with a chosen set of items of varying value so as to maximize the total packed value:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{equation*}
\begin{aligned}
&amp;amp; \underset{x}{\text{maximize}}
&amp;amp; &amp;amp; V = \sum_{i=1}^n v_i x_i \\
&amp;amp; \text{subject to}
&amp;amp; &amp;amp; \sum_{i=1}^n w_i x_i \leq W \\
&amp;amp; &amp;amp; &amp;amp; x_i \in \{0,1\} \text{ for all } i \text{ in } \{1,\dots,n\}
\end{aligned}
\end{equation*}
\]&lt;/span&gt;
We have &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; items of integral&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; weights &lt;span class=&#34;math inline&#34;&gt;\(w_i &amp;gt; 0\)&lt;/span&gt; and value &lt;span class=&#34;math inline&#34;&gt;\(v_i\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt; is the knapsack weight capacity. Each item is either chosen or not, hence the “0/1” in the name.&lt;/p&gt;
&lt;p&gt;Since all &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; are restricted to be binary (boolean), this is an integer linear problem with a search space size of &lt;span class=&#34;math inline&#34;&gt;\(2^n\)&lt;/span&gt;. It can be given to an MILP solver. But because of a simple nested structure the problem also has a straightforward dynamic programming (DP) solution that I can code in a few lines.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;DP&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Dynamic programming algorithm&lt;/h2&gt;
&lt;p&gt;Assume the problem has been solved for all knapsack capacities up to some &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; while making use of only a subset of items &lt;span class=&#34;math inline&#34;&gt;\(1, \dots, j\)&lt;/span&gt;, and let &lt;span class=&#34;math inline&#34;&gt;\(V(w, j)\)&lt;/span&gt; be the solution, i.e. the maximum achievable knapsack value. Now consider all smaller subproblems without item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(V(w&amp;#39;, j-1)\)&lt;/span&gt; for all possible &lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39;\)&lt;/span&gt;. &lt;span class=&#34;math inline&#34;&gt;\(V(w, j)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V(w&amp;#39;, j-1)\)&lt;/span&gt; are connected with a single “move” of looking at item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and deciding to either include it in the optimal selection for knapsack &lt;span class=&#34;math inline&#34;&gt;\(V(w, j)\)&lt;/span&gt; or not:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if including item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is a move that’s feasible (&lt;span class=&#34;math inline&#34;&gt;\(w_j \leq w\)&lt;/span&gt;) then &lt;span class=&#34;math inline&#34;&gt;\(V(w, j)\)&lt;/span&gt; is the best of &lt;span class=&#34;math inline&#34;&gt;\(v_j + V(w&amp;#39;, j - 1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(V(w&amp;#39;, j - 1)\)&lt;/span&gt; depending on whether the move is “optimal” (improves &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt;) or not; in the former case &lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39; = w - w_j\)&lt;/span&gt; and in the latter &lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39; = w\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;if including item &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is not feasible (&lt;span class=&#34;math inline&#34;&gt;\(w_j &amp;gt; w\)&lt;/span&gt;) then &lt;span class=&#34;math inline&#34;&gt;\(V(w, j) = V(w&amp;#39;, j - 1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(w&amp;#39; = w\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(V(w, 1)\)&lt;/span&gt; is 0 or &lt;span class=&#34;math inline&#34;&gt;\(v_1\)&lt;/span&gt; depending on whether the first item fits within capacity &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, knapsack subproblems have a recurrent relationship for &lt;span class=&#34;math inline&#34;&gt;\(j &amp;gt; 1\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  V(w, j) =
  \left\{
    \begin{array}{@{}ll@{}}
      V(w , j - 1) &amp;amp; \text{if}\ w \lt w_j, \\
      \max \big\{v_j + V(w - w_j, j - 1),V(w , j - 1)\big\} , &amp;amp; \text{otherwise} \\
    \end{array}
  \right.
\]&lt;/span&gt;
together with a boundary condition for &lt;span class=&#34;math inline&#34;&gt;\(j = 1\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
  V(w, 1) =
  \left\{
    \begin{array}{@{}ll@{}}
      0 &amp;amp; \text{if}\ w \lt w_1, \\
      v_1, &amp;amp; \text{otherwise} \\
    \end{array}
  \right.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(The above could be stated more compactly if &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; started at 0 and &lt;span class=&#34;math inline&#34;&gt;\(V(w,0)\)&lt;/span&gt; were defined as 0.)&lt;/p&gt;
&lt;p&gt;To capture inputs into a problem instance, I will use an array of Julia &lt;code&gt;struct&lt;/code&gt;s. Although I could get away with a list or a tuple, I think a &lt;code&gt;struct&lt;/code&gt; makes for more readable example code:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;struct Item
    value   ::Int64
    weight  ::Int64
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(V(w, j)\)&lt;/span&gt; is represented as a matrix (another first-class citizen in Julia), a non-recursive implementation would be to sweep the space of &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; going from smaller to larger item sets:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function opt_value(W ::Int64, items ::Array{Item}) ::Int64
    n = length(items)

    # V[w,j] stores opt value achievable with capacity &amp;#39;w&amp;#39; and using items &amp;#39;1..j&amp;#39;:

    V = Array{Int64}(undef, W, n) # W×n matrix with uninitialized storage

    # initialize first column v[:, 1] to trivial single-item solutions:

    V[:, 1] .= 0
    V[items[1].weight:end, 1] .= items[1].value

    # do a pass through remaining columns:

    for j in 2 : n
        itemⱼ = items[j]
        for w in 1 : W
            V_without_itemⱼ = V[w, j - 1]
            V_allow_itemⱼ = (w &amp;lt; itemⱼ.weight
                ? V_without_itemⱼ
                : (itemⱼ.value + (w ≠ itemⱼ.weight ? V[w - itemⱼ.weight, j - 1] : 0)))
            V[w, j] = max(V_allow_itemⱼ, V_without_itemⱼ)
        end
    end

    return V[W, n]
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That loop is almost a straightforward translation of my recurrence, although the body needs some extra edge condition checks. Note the familiar &lt;code&gt;?:&lt;/code&gt; syntax for ternary operator and some comforting exploitation of Julia’s support for Unicode math symbols.&lt;/p&gt;
&lt;p&gt;This may not be the best bit of Julia code you’ll ever see, but I’ve literally just learned enough syntax for my first experiment here. One performance-related concession to Julia has already been included above by arranging to traverse &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; in column-major order. Yes, Julia opts for R/MATLAB/Fortran design choice here and that is not under end user control, as far as I can tell at this point. Right now, it does feel like R and yet awkwardly different from C++, which would be my production choice for this particular problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-obvious-improvement&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An obvious improvement&lt;/h2&gt;
&lt;p&gt;Notice also that I cheat a little and do not compute half of the solution, specifically the optimal &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;’s&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. This is to keep the experiment simple and focus on iterative performance only. However, since this means I don’t need to capture the optimal solution structure in &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; matrix, I don’t need to allocate it: it is sufficient to allocate a couple of buffers for columns &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j-1\)&lt;/span&gt; and re-use them as needed:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function opt_value(W ::Int64, items ::Array{Item}) ::Int64
    n = length(items)

    V = zeros(Int64, W) # single column of size W, zero-initialized
    V_prev = Array{Int64}(undef, W) # single column of size W, uninitialized storage

    V[items[1].weight:end] .= items[1].value

    for j in 2 : n
        V, V_prev = V_prev, V
        itemⱼ = items[j]
        for w in 1 : W
            V_without_itemⱼ = V_prev[w]
            V_allow_itemⱼ = (w &amp;lt; itemⱼ.weight
                ? V_without_itemⱼ
                : (itemⱼ.value + (w ≠ itemⱼ.weight ? V_prev[w - itemⱼ.weight] : 0)))
            V[w] = max(V_allow_itemⱼ, V_without_itemⱼ)
        end
    end

    return V[W]
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This version will now scale to quite large problem instances.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;algorithm-speed-julia-vs-python-vs-java-vs-c&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Algorithm speed: Julia vs Python vs Java vs C++&lt;/h2&gt;
&lt;p&gt;To measure performance, I use the &lt;code&gt;@elapsed&lt;/code&gt; macro from Julia’s &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#Base.@time&#34;&gt;family of &lt;code&gt;@time&lt;/code&gt; and friends&lt;/a&gt; with randomly constructed problem instances of different scale. Because Julia is JIT-based I need to be careful and do a few timing repeats after burning the very first measurement.&lt;/p&gt;
&lt;p&gt;Actually, I’ll use the median of 5 repeats which is even more robust:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function run(repeats = 5)
    @assert repeats &amp;gt; 1

    times = zeros(Float64, repeats)
    seed = 12345

    for W in [5_000, 10_000, 20_000, 40_000, 80_000]
        for repeat in 1 : repeats
            spec = make_random_data(W, seed += 1)
            times[repeat] = @elapsed opt_value(spec[1], spec[2])
        end
        sort!(times)
        println(W, &amp;quot;, &amp;quot;, times[(repeats + 1) ÷ 2])
    end
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the promised language shootout, I’ve implemented this same algorithm in three other languages: Python, Java, and C++. I event went as far as make sure that all “ports” used similar array data types and even the exact same random number generator for building the exact same random problem instances. To maintain consistency with statically typed languages (Java, C++), I ensure that value types used by the dynamic versions are 64-bit integers as much as possible – this required some minor contortions in Python.&lt;/p&gt;
&lt;p&gt;Here’s the C++ version of &lt;code&gt;opt_value()&lt;/code&gt; (you can get all four language versions from &lt;a href=&#34;https://github.com/vladium/study_julia_with_me/tree/master/knapsack_benchmark&#34;&gt;this github repo&lt;/a&gt;, there is a single source file per language that’s trivial to compile and run):&lt;/p&gt;
&lt;pre class=&#34;cpp&#34;&gt;&lt;code&gt;int64_t
opt_value (int64_t const W, std::vector&amp;lt;item&amp;gt; const &amp;amp; items)
{
    auto const n = items.size ();

    std::unique_ptr&amp;lt;int64_t []&amp;gt; const v_data { std::make_unique&amp;lt;int64_t []&amp;gt; (W) }; // &amp;quot;zeros&amp;quot;
    std::unique_ptr&amp;lt;int64_t []&amp;gt; const v_prev_data { std::make_unique&amp;lt;int64_t []&amp;gt; (W) }; // &amp;quot;zeros&amp;quot;

    int64_t * V { v_data.get () };
    int64_t * V_prev { v_prev_data.get () };

    for (int64_t w = items[0].weight; w &amp;lt;= W; ++ w)
        V[w - 1] = items[0].value;

    for (std::size_t j = 1; j &amp;lt; n; ++ j)
    {
        std::swap (V, V_prev);
        item const &amp;amp; item { items [j] };
        
        for (int64_t w = 1; w &amp;lt;= W; ++ w)
        {
            auto const V_without_item_j = V_prev[w - 1];
            auto const V_allow_item_j = (w &amp;lt; item.weight
                ? V_without_item_j
                : (item.value + (w != item.weight ? V_prev[w - 1 - item.weight] : 0)));

            V[w - 1] = std::max(V_allow_item_j, V_without_item_j);
         }
    }

    return V[W - 1];
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve tried to keep the implementation consistent and idiomatic within each language. (It helps that my algorithm is basically a couple of nested loops without memory allocation, some arithmetic, and not much else.) All these implementations could in principle be tuned further using language-specific techniques, but that’s not my goal here.&lt;/p&gt;
&lt;p&gt;Here is a snippet of calculation latency data for &lt;span class=&#34;math inline&#34;&gt;\(W=80000\)&lt;/span&gt;, captured on the exact same CPU:&lt;/p&gt;
&lt;table style=&#39;width:100%;&#39;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
lang
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
W
&lt;/th&gt;
&lt;th style=&#34;text-align:center;&#34;&gt;
time (sec)
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
julia
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
80000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.1135
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
python
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
80000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
28.2094
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
java
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
80000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0781
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
c++
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
80000
&lt;/td&gt;
&lt;td style=&#34;text-align:center;&#34;&gt;
0.0710
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Hmm. Perhaps you begin to suspect that Python is not going to win this. Here is a log-log plot of all data, for all &lt;span class=&#34;math inline&#34;&gt;\(W\)&lt;/span&gt;’s:&lt;/p&gt;
&lt;div class=&#34;figure&#34; style=&#34;text-align: center&#34;&gt;&lt;span id=&#34;fig:fraction&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/tutorials/study_julia_with_me/knapsack_benchmark_files/figure-html/fraction-1.png&#34; alt=&#34;Calculation time as a function of knapsack problem size. (Note that both axes use log scale.)&#34; width=&#34;75%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Calculation time as a function of knapsack problem size. (Note that both axes use log scale.)
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Julia is about 50% slower than either Java or C++. But it is Python that is the real laggard in the group: slower by &lt;strong&gt;more than 100x&lt;/strong&gt; across the entire range of tested problem sizes. Ouch!&lt;/p&gt;
&lt;p&gt;Going back to the matrix version of the algorithm, you can see how the matrix is accessed predictably over &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; columns but somewhat randomly (in a data-depedent fashion) over &lt;span class=&#34;math inline&#34;&gt;\(w\)&lt;/span&gt; rows. There doesn’t seem to be a way to express the algorithm in linear algebra operations. This difficulty is retained in the optimized two-column-buffer version. The algorithm is short and simple but there just doesn’t seem to be a way to vectorize it so that it would be fast, say, in numpy. Massive underperformance of the Python version is the cost I pay for slow &lt;em&gt;interpretation&lt;/em&gt; of &lt;a href=&#34;https://opensource.com/article/18/4/introduction-python-bytecode&#34;&gt;Python bytecode&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As for Julia, so far so good. I might just get used to the “no need to vectorize code to make it fast” lifestyle.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Restricting weights to be integral is not crucial to my test here but could make the problem statement acceptable to more solver types.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Some might argue that &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;’s are in fact &lt;em&gt;more&lt;/em&gt; than half of the solution. Ok, so I cheat a lot.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Julia type annotations: what Python &#39;type hints&#39; wish they were</title>
      <link>/tutorials/study_julia_with_me/type_annotations/</link>
      <pubDate>Fri, 25 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/tutorials/study_julia_with_me/type_annotations/</guid>
      <description>

&lt;p&gt;Julia is unusual in that it is a dynamically typed language (meaning you don&amp;rsquo;t have to declare variable types &amp;ldquo;statically&amp;rdquo;, in program text), while at the same time supporting a rich mechanism for communicating type information to the JIT compiler and runtime. Effectively, Julia has both dynamic and static typing. When provided, static type information can have non-trivial impact on Julia code behavior, both in terms of functionality and performance.&lt;/p&gt;

&lt;p&gt;This distinctive typing seems to be one of the defining features of Julia. To keep tutorials to a reasonable length, I cover basics here and delay further case studies (parameterized types, overloading, multiple dispatch) until the next one.&lt;/p&gt;

&lt;h4 id=&#34;preview&#34;&gt;Preview&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;A quick tour of Julia type taxonomy.&lt;/li&gt;
&lt;li&gt;Drill into &lt;em&gt;type annotations&lt;/em&gt; and understand their impact on: code documentation, correctness, performance.&lt;/li&gt;
&lt;li&gt;Julia functions are always &amp;ldquo;virtual&amp;rdquo;. Julia supports &lt;em&gt;functional OOP&lt;/em&gt; as a paradigm.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;types-and-inheritance&#34;&gt;Types and inheritance&lt;/h1&gt;

&lt;p&gt;Everything in Julia that is a value also has a type and the types are first-class objects (think &lt;code&gt;T.class&lt;/code&gt; in Java or &lt;code&gt;T.__type__&lt;/code&gt; in Python). Subtyping relationships are set up and queried with the &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#Core.:%3C:&#34; target=&#34;_blank&#34;&gt;&amp;lt;: subtype operator&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; typeof(1)
Int64

julia&amp;gt; supertype(typeof(1))
Signed

julia&amp;gt; typeof(1) &amp;lt;: supertype(typeof(2))
true

julia&amp;gt; Int64 &amp;lt;: Signed
true

julia&amp;gt; Int64 &amp;gt;: Signed # there is also a &#39;supertype operator&#39;, used trivially here but more useful for parameterized types
false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Types known to a given runtime session form a tree (a directed graph, actually) rooted at &lt;code&gt;Any&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;speaking-of-type-trees&#34;&gt;Speaking of [type] trees&lt;/h3&gt;

&lt;p&gt;I found it handy to explore subtrees within this graph of types using the following helper function. It builds on &lt;code&gt;subtypes()&lt;/code&gt; from &lt;a href=&#34;https://github.com/JuliaStdlibs/InteractiveUtils.jl&#34; target=&#34;_blank&#34;&gt;InteractiveUtils.jl&lt;/a&gt;, which would be already imported and availalbe if you&amp;rsquo;re in REPL but may need an &lt;code&gt;import&lt;/code&gt; in a script:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;import InteractiveUtils

function subtypetree(T, depth = 0) # you might also want to add &#39;max_depth&#39;...
    println(&#39;\t&#39; ^ depth, T)
    for t in InteractiveUtils.subtypes(T)
        subtypetree(t, depth + 1)
    end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;arithmetic-types&#34;&gt;Arithmetic types&lt;/h2&gt;

&lt;p&gt;There is a collection of (ahem) typical types for arithmetic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Int8&lt;/code&gt;, &amp;hellip;, &lt;code&gt;Int64&lt;/code&gt;, &lt;code&gt;Int128&lt;/code&gt;, plus unsigned variants,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Float16&lt;/code&gt;, &lt;code&gt;Float32&lt;/code&gt;, &lt;code&gt;Float64&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BigInt&lt;/code&gt; and &lt;code&gt;BigFloat&lt;/code&gt;,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;organized in this hierarchy:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; subtypetree(Number)
Number
    Complex
    Real
        AbstractFloat
            BigFloat
            Float16
            Float32
            Float64
        AbstractIrrational
            Irrational
        Integer
            Bool
            Signed
                BigInt
                Int128
                Int16
                Int32
                Int64
                Int8
            Unsigned
                UInt128
                UInt16
                UInt32
                UInt64
                UInt8
        Rational
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first thing that struck me here is Julia&amp;rsquo;s keeping with its emphasis on performance: Julia integers are &lt;em&gt;not&lt;/em&gt; &amp;ldquo;big&amp;rdquo; by default (contrast with &lt;a href=&#34;https://docs.python.org/3/library/stdtypes.html#typesnumeric&#34; target=&#34;_blank&#34;&gt;Python 3&lt;/a&gt;). And the rich spectrum of arithmetic bit widths is meaningful: &lt;code&gt;Float16&lt;/code&gt; and &lt;code&gt;Float32&lt;/code&gt; could be useful for GPU computing, while wide &lt;code&gt;Int&lt;/code&gt;-types could work with SSE/AVX/etc instructions and/or support efficient interfacing with native code. (I say &amp;ldquo;could&amp;rdquo; because I have no idea yet if that&amp;rsquo;s really the case.)&lt;/p&gt;

&lt;h2 id=&#34;primitive-types&#34;&gt;Primitive types&lt;/h2&gt;

&lt;p&gt;Turns out all of these arithmetic types are not what you&amp;rsquo;d call &amp;ldquo;built into the compiler&amp;rdquo; but are rather defined in the language itself, as standard primitive types&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:This-is-what-the&#34;&gt;&lt;a href=&#34;#fn:This-is-what-the&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;primitive type Bool  &amp;lt;: Integer   8 end
primitive type Int64 &amp;lt;: Signed   64 end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The syntax is&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;primitive type «name» &amp;lt;: «supertype» «bits» end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where the supertype is optional (and defaults to &lt;code&gt;Any&lt;/code&gt;). I can apparently define my own primitive type, a 24-bit integer&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:As-I-write-this&#34;&gt;&lt;a href=&#34;#fn:As-I-write-this&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; primitive type Int24 &amp;lt;: Signed 24 end

julia&amp;gt; subtypetree(Number)
Number
    Complex
    Real
        ...
        Integer
            Bool
            Signed
                ...
                Int24
                ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(This is great&amp;hellip; but how do I construct an &lt;code&gt;Int24&lt;/code&gt; or define arithmetic? Julia docs are not clear on that &amp;ndash; I think I know how to proceed but that is outside of today&amp;rsquo;s scope.)&lt;/p&gt;

&lt;h2 id=&#34;mutable&#34;&gt;Concrete vs abstract types&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ve already used a &lt;code&gt;struct&lt;/code&gt; in the &lt;a href=&#34;../knapsack_benchmark#DP&#34;&gt;knapsack benchmark&lt;/a&gt; to represent knapsack items as instances of this type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;struct Item
    value   ::Int64
    weight  ::Int64
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These are straightforward: &lt;code&gt;Item&lt;/code&gt;s contain fields (the type is &lt;strong&gt;composite&lt;/strong&gt;) and can be instantiated (the type is &lt;strong&gt;concrete&lt;/strong&gt;). They can also be examined at runtime using Julia&amp;rsquo;s &lt;em&gt;reflection facilities&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; sizeof(Item)
16

julia&amp;gt; fieldcount(Item)
2

julia&amp;gt; fieldnames(Item)
(:value, :weight)

julia&amp;gt; fieldtypes(Item)
(Int64, Int64)

julia&amp;gt; function showfields(T)
           for i in 1 : fieldcount(T)
               println(fieldoffset(T, i), &#39;\t&#39;, fieldname(T, i), &amp;quot;\t::&amp;quot;, fieldtype(T, i))
           end
       end
showfields (generic function with 1 method)

julia&amp;gt; showfields(Item)
0   value   ::Int64
8   weight  ::Int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;but a few things here are less obvious:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;struct&lt;/code&gt;s default to being &lt;strong&gt;immutable&lt;/strong&gt; unless explicitly marked as &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#mutable%20struct&#34; target=&#34;_blank&#34;&gt;mutable&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;they are always &lt;strong&gt;final&lt;/strong&gt;, i.e. cannot be further inherited from&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:Just-like-classe&#34;&gt;&lt;a href=&#34;#fn:Just-like-classe&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. (This is also true of primitive and, in fact, any non-abstract types.)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Defaulting to immutability is not an arbitrary choice. It can be exploited by the compiler to optimize performance and memory usage by &lt;a href=&#34;https://en.wikipedia.org/wiki/String_interning&#34; target=&#34;_blank&#34;&gt;&amp;ldquo;interning&amp;rdquo;&lt;/a&gt; values that are &lt;em&gt;indistinguishable&lt;/em&gt; if they are equal. Compare&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; i1 = Item(1, 2)
Item(1, 2)

julia&amp;gt; i2 = Item(1, 2)
Item(1, 2)

julia&amp;gt; i1 == i2  # equal
true

julia&amp;gt; i1 === i2 # actually, the same &amp;quot;interned&amp;quot; object
true

julia&amp;gt; i1 == Item(1, 3)
false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; mutable struct MutableItem # mutable version of &#39;Item&#39;
           value   ::Int64
           weight  ::Int64
       end

julia&amp;gt; i1 = MutableItem(1, 2)
MutableItem(1, 2)

julia&amp;gt; i2 = MutableItem(1, 2)
MutableItem(1, 2)

julia&amp;gt; i1 == i2  # not equal!
false # &amp;lt;- surprised? looks like &#39;==&#39; needs to be defined for custom mutable types...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Julia also has &lt;strong&gt;abstract types&lt;/strong&gt; which can&amp;rsquo;t be instantiated, but are instead used to organize the type graph via shared parent nodes. You could also say they act as &amp;ldquo;marker&amp;rdquo; or &amp;ldquo;trait&amp;rdquo; base classes, like &lt;code&gt;Number&lt;/code&gt; or &lt;code&gt;Signed&lt;/code&gt; above. Since all non-abstract Julia types are &lt;em&gt;final&lt;/em&gt;, any supertype is necessarily an abstract type (&lt;code&gt;Any&lt;/code&gt; if not specified explicitly).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; abstract type MyInt &amp;lt;: Int32 end
ERROR: invalid subtyping in definition of MyInt
Stacktrace:
 [1] ...

julia&amp;gt; abstract type MyInt &amp;lt;: supertype(Int32) end

julia&amp;gt; subtypetree(Number)
Number
    Complex
    Real
        ...
        Integer
            Bool
            Signed
                ...
                Int24
                ...
                MyInt
        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;type-parameters&#34;&gt;Type parameters&lt;/h2&gt;

&lt;p&gt;To various degrees, all of the three major categories of Julia types (primitive, composite, abstract) are available in other dynamic languages, either natively or via some &lt;a href=&#34;https://docs.python.org/3/library/abc.html&#34; target=&#34;_blank&#34;&gt;libraries&lt;/a&gt;. Julia also offers something that gets it if not into the realm of uber-powerful (and uber-complicated) &lt;a href=&#34;http://www.tmplbook.com/&#34; target=&#34;_blank&#34;&gt;C++ metaprogramming&lt;/a&gt;, then definitely into the realm of &lt;a href=&#34;https://en.wikipedia.org/wiki/Generics_in_Java&#34; target=&#34;_blank&#34;&gt;Java generics&lt;/a&gt;: all three type categories can be further &lt;em&gt;parameterized&lt;/em&gt; with other types and values. I&amp;rsquo;ll explore this in a future tutorial.&lt;/p&gt;

&lt;h1 id=&#34;type-annotations&#34;&gt;Type annotations&lt;/h1&gt;

&lt;p&gt;And now to the meat of this tutorial: type annotations. A &lt;em&gt;type annotation&lt;/em&gt; in Julia looks like &lt;code&gt;&amp;lt;thing&amp;gt;::&amp;lt;type&amp;gt;&lt;/code&gt;&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:I-use-an-extra-b&#34;&gt;&lt;a href=&#34;#fn:I-use-an-extra-b&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; &amp;ndash; it is an in-place modifier to a &lt;code&gt;&amp;lt;thing&amp;gt;&lt;/code&gt; introduced by the &lt;code&gt;::&lt;/code&gt; operator.&lt;/p&gt;

&lt;h2 id=&#34;tasvsconv&#34;&gt;Typeasserts vs variable declarations&lt;/h2&gt;

&lt;p&gt;The way I read the documentation, Julia type annotations can be applied to two types of &lt;code&gt;&amp;lt;thing&amp;gt;&lt;/code&gt;s:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;[&lt;strong&gt;typeassert&lt;/strong&gt;] expressions computing a value (and recall that &lt;em&gt;everything&lt;/em&gt; in Julia is an &lt;a href=&#34;https://en.wikipedia.org/wiki/Expression_(computer_science)&#34; target=&#34;_blank&#34;&gt;expression&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;x = y ::Float64 # promises to the runtime that at this point in the execution &#39;y&#39; will be a Float64
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;[&lt;strong&gt;variable type declaration&lt;/strong&gt;] left-hand sides of assignments or declarations that introduce (local) variables:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;x ::Float64 = y # declares a new local &#39;x&#39;, marks it as always containing Float64 values, and initializes with &#39;y&#39; converted to Float64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This second case also covers typed fields of &lt;code&gt;struct&lt;/code&gt;s and named tuples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;struct Point
  x ::Float64 # this field will always contain only Float64 values
  y           # this field can contain any Julia value
end
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first case is a &lt;em&gt;typeassert&lt;/em&gt;. The second kind of annotation marks the name/field to its left as constrained to values compatible with the given type, and also ensures that throughout the variable&amp;rsquo;s scope all subsequent initializations of and assignments to it are filtered through an implicit &lt;em&gt;conversion&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;As a consequence, there are differences in runtime behavior and the information communicated to the system:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;With a &lt;em&gt;typeassert&lt;/em&gt; the compiler will create code that at runtime will &lt;em&gt;check&lt;/em&gt; the annotated value for type compatibility and throw a &lt;code&gt;TypeError&lt;/code&gt; if the check fails &amp;ndash; but it will &lt;em&gt;not&lt;/em&gt; attempt to coerce the computed value to the annotation type in any way. Type-asserted syntax &lt;tt&gt;&amp;lt;exp&amp;gt;::T&lt;/tt&gt; is precisely equivalent to a call, possibly inlined, to &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#Core.typeassert&#34; target=&#34;_blank&#34;&gt;typeassert(&amp;lt;exp&amp;gt;, T)&lt;/a&gt; followed by making use of the &lt;tt&gt;&amp;lt;exp&amp;gt;&lt;/tt&gt; value.&lt;/li&gt;
&lt;li&gt;With a &lt;em&gt;variable type declaration&lt;/em&gt; any assignment &lt;tt&gt;&amp;lt;lhs&amp;gt;::T&amp;nbsp;=&amp;nbsp;&amp;lt;rhs&amp;gt;&lt;/tt&gt; will effectively translate into &lt;tt&gt;&amp;lt;lhs&amp;gt;&amp;nbsp;=&amp;nbsp;convert(T, &amp;lt;rhs&amp;gt;)&lt;/tt&gt;, i.e. contain a call, possibly inlined, to &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#Base.convert&#34; target=&#34;_blank&#34;&gt;convert(T, &amp;lt;rhs&amp;gt;)&lt;/a&gt;. And at runtime, every such assignment will attempt to coerce its right hand-side value to &lt;tt&gt;T&lt;/tt&gt;, possibly resulting in a value that&amp;rsquo;s only an approximation. Should this conversion fail, an exception will be thrown:

&lt;ul&gt;
&lt;li&gt;if no such conversion exists at all, a &lt;code&gt;MethodError&lt;/code&gt; is thrown;&lt;/li&gt;
&lt;li&gt;if &lt;tt&gt;T&lt;/tt&gt; is an &lt;code&gt;Integer&lt;/code&gt; (sub)type and cannot represent the expression value, an &lt;code&gt;InexactError&lt;/code&gt; is thrown.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;To appreciate the difference, compare&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; function foo()
         x ::Float64 = 1 # implies &#39;convert(Float64, 1)&#39;
         x, typeof(x)
       end
foo (generic function with 1 method)

julia&amp;gt; foo()
(1.0, Float64)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; function foo()
         x = 1 ::Float64 # implies &#39;typeassert(1, Float64)&#39;
         x, typeof(x)
       end
foo (generic function with 1 method)

julia&amp;gt; foo()
ERROR: TypeError: in typeassert, expected Float64, got Int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Literal &lt;tt&gt;1&lt;/tt&gt; is of a (machine-dependent) &lt;code&gt;Int&lt;/code&gt; type:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; typeof(1)
Int64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and even though it can be converted to a &lt;code&gt;Float64&lt;/code&gt; without loss, such a conversion is not even attempted in the second version of &lt;code&gt;foo()&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    As I write this, Julia does not yet support type declarations for &lt;em&gt;global&lt;/em&gt; variables &amp;ndash; this is the reason I wrapped the above examples into functions.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;what-about-function-signatures&#34;&gt;What about function signatures?&lt;/h2&gt;

&lt;p&gt;Unsurprisingly, it is also possible to type-annotate function arguments and return types:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function bar(x ::Float64) ::Float32
    sin(2π * x)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;function-arguments&#34;&gt;Function arguments&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;re coming from languages like C++ or Java where type conversions can happen as part of argument passing, you might think that &lt;tt&gt;x ::Float64&lt;/tt&gt; in &lt;code&gt;bar()&lt;/code&gt; is like a local (typed) variable declaration, similar to the &lt;a href=&#34;#tasvsconv&#34;&gt;second case above&lt;/a&gt;, perhaps implying a call to something like &lt;strong&gt;convert(Float64, x)&lt;/strong&gt; everywhere before &lt;code&gt;bar()&lt;/code&gt; is invoked. That is not the case in Julia: no conversions ever take place as part of Julia function argument passing. In fact, Julia argument type annotations are actually more like those typeasserts: &lt;tt&gt;foo(x)&lt;/tt&gt; will &lt;em&gt;expect&lt;/em&gt; &lt;tt&gt;x&lt;/tt&gt; to be a &lt;code&gt;Float64&lt;/code&gt; already.&lt;/p&gt;

&lt;p&gt;There is a subtle difference from an in-place typeassert, however: with the above definition of &lt;code&gt;bar()&lt;/code&gt; there will be no need to generate an implicit call to &lt;strong&gt;typeassert()&lt;/strong&gt; at all because I will &lt;em&gt;only&lt;/em&gt; be allowed to call it with &lt;code&gt;Float64&lt;/code&gt;s. If I need &lt;tt&gt;sin(2π&amp;nbsp;*&amp;nbsp;x)&lt;/tt&gt; for a &lt;code&gt;Float64&lt;/code&gt; input &lt;code&gt;x&lt;/code&gt;, no problem. For any other type&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:To-simply-the-na&#34;&gt;&lt;a href=&#34;#fn:To-simply-the-na&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;, say, &lt;code&gt;Int64&lt;/code&gt;, I will get a flat rejection not because a method call was tried and failed during &lt;code&gt;Int64&lt;/code&gt;-to-&lt;code&gt;Float64&lt;/code&gt; input type conversion (&lt;code&gt;TypeError&lt;/code&gt;) but because the requisite method (named &amp;ldquo;foo&amp;rdquo; and taking a single argument of type &lt;code&gt;Int64&lt;/code&gt;) did not exist (&lt;code&gt;MethodError&lt;/code&gt;). And since &lt;code&gt;Float64&lt;/code&gt; is a concrete type and, again, all concrete types are &lt;em&gt;final&lt;/em&gt; in Julia, the universe of possible outcomes here shrinks dramatically:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; bar(0.75)
-1.0f0

julia&amp;gt; bar(1.)
-2.4492937f-16

julia&amp;gt; bar(1)
ERROR: MethodError: no method matching bar(::Int64)
Closest candidates are:
  bar(::Float64) at ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may seem a little draconian, but it is connected to how Julia&amp;rsquo;s &lt;em&gt;multiple dispatch&lt;/em&gt; works and is further ameliorated by Julia&amp;rsquo;s system of &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/conversion-and-promotion/&#34; target=&#34;_blank&#34;&gt;promoting function arguments to a common type&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;function-return-types&#34;&gt;Function return types&lt;/h3&gt;

&lt;p&gt;Specifying &lt;code&gt;bar()&lt;/code&gt; return type to be &lt;code&gt;Float32&lt;/code&gt; is a way to ensure that value being returned is passed through a &lt;strong&gt;convert(Float32, &amp;hellip;)&lt;/strong&gt;. Whether this is desired depends on software design. I can imagine situations where it could be used as a way to safely return &amp;ldquo;special&amp;rdquo; values:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function sqrt_or_nothing(x ::Float64) ::Union{Float64, Nothing}
    x &amp;lt; 0.0 ? nothing : √x
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; @show sqrt_or_nothing(2.0)
sqrt_or_nothing(2.0) = 1.4142135623730951
1.414213562373095

julia&amp;gt; @show sqrt_or_nothing(-2.0)
sqrt_or_nothing(-2.0) = nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, it might be easier to reason about your code behavior if most functions are strict about their return value types. Otherwise, it seems like it could be easy in Julia to accidentally return &lt;em&gt;different types along different value return paths&lt;/em&gt;, which could cause inefficiencies or maybe even errors downstream:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function bar_clipped(x ::Float64)
    x &amp;lt; 0.0 ? 0 : sin(2π * x)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; typeof(bar_clipped(0.75))
Float64

julia&amp;gt; typeof(bar_clipped(-0.75))
Int64 # oops, use 0.0 literal instead of 0 above
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;when-are-implicit-conversions-done&#34;&gt;When are implicit conversions done?&lt;/h2&gt;

&lt;p&gt;Most of the cases of implicit calls to &lt;strong&gt;convert(&amp;hellip;)&lt;/strong&gt; have already been mentioned. Julia &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/conversion-and-promotion/&#34; target=&#34;_blank&#34;&gt;documentation&lt;/a&gt; offers this complete list:&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Assigning to an array converts to the array&amp;rsquo;s element type.&lt;/li&gt;
&lt;li&gt;Assigning to a field of an object converts to the declared type of the field.&lt;/li&gt;
&lt;li&gt;Constructing an object with new converts to the object&amp;rsquo;s declared field types.&lt;/li&gt;
&lt;li&gt;Assigning to a variable with a declared type (e.g. local x::T) converts to that type.&lt;/li&gt;
&lt;li&gt;A function with a declared return type converts its return value to that type.&lt;/li&gt;
&lt;li&gt;Passing a value to ccall converts it to the corresponding argument type.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;case-study-functional-oop&#34;&gt;Case study: functional OOP&lt;/h1&gt;

&lt;p&gt;So far, Julia type annotations appeared to be potentially beneficial (for code maintenance, performance), yet somehow optional, feature of the language. Let me now show a situation where annotation are truly &lt;em&gt;necessary&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We saw how every function argument in Julia is always associated with a type. Is it possible for there to be &lt;em&gt;multiple&lt;/em&gt; functions that all have the same name but different parameter types?&lt;/p&gt;

&lt;p&gt;Not only is the answer &amp;ldquo;yes&amp;rdquo;, it is actually kind of like &amp;ldquo;yes, it is meant to happen &lt;em&gt;a lot&lt;/em&gt;&amp;ldquo;: Julia thrives on maintaining multiple versions of the &amp;ldquo;same&amp;rdquo; function (called &amp;ldquo;methods&amp;rdquo;) and figuring out which version to invoke for a given set of inputs. These versions are distinguished by annotating parameters with different types. Enter &amp;ldquo;multiple dispatch&amp;rdquo;, a &lt;strong&gt;&lt;em&gt;core paradigm&lt;/em&gt;&lt;/strong&gt; of Julia programming&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:From-what-I-can&#34;&gt;&lt;a href=&#34;#fn:From-what-I-can&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. The intuition is that Julia functions are essentially &amp;ldquo;always virtual&amp;rdquo;: unlike other languages where a class method needs to be marked in a special way to support &amp;ldquo;late binding&amp;rdquo; (method dispatch based on runtime, not compile, type of an object), Julia runtime system always dispatches &lt;em&gt;all&lt;/em&gt; functions on the &lt;em&gt;concrete runtime types&lt;/em&gt; of &lt;em&gt;all&lt;/em&gt; their arguments. Because no argument position is &amp;ldquo;special&amp;rdquo; and the method does not &amp;ldquo;belong&amp;rdquo; to any particular parameter type, this form of polymorphism usually opts for language design with standalone functions, that is functions that do not live inside any &amp;ldquo;classes&amp;rdquo;. Some people call such designs &amp;ldquo;functional OOP&amp;rdquo;. It makes a lot of sense for math-style coding due to symmetries in function parameters.&lt;/p&gt;

&lt;p&gt;Now, one way to ease into Julia multiple dispatch is to consider its simplest edge case: &lt;em&gt;single&lt;/em&gt; dispatch.&lt;/p&gt;

&lt;h2 id=&#34;serializing-julia-objects-to-json&#34;&gt;Serializing Julia objects to JSON&lt;/h2&gt;

&lt;p&gt;I am going to implement a simple serializer of Julia objects to &lt;a href=&#34;https://en.wikipedia.org/wiki/JSON&#34; target=&#34;_blank&#34;&gt;JSON&lt;/a&gt;. This will be a &lt;a href=&#34;https://github.com/vladium/study_julia_with_me/tree/master/type_annotations/Tutorial.jl&#34; target=&#34;_blank&#34;&gt;toy example&lt;/a&gt;, useless in any kind of production setting. My initial point is the &amp;ldquo;interface&amp;rdquo; method &lt;tt&gt;to_JSON()&lt;/tt&gt; calling &lt;tt&gt;visit()&lt;/tt&gt; that in turn starts as a single fallback that always fails:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function to_JSON(io ::IO, obj)
    visit(obj, io)
end

function visit(obj, io ::IO)
    error(&amp;quot;default visit() called for obj type: &amp;quot;, typeof(obj))
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am going to anchor my design in the &amp;ldquo;virtual nature&amp;rdquo; of &lt;tt&gt;visit(obj,&amp;nbsp;io)&lt;/tt&gt;, with execution routed based on the runtime type of &lt;tt&gt;obj&lt;/tt&gt;. Looking at my &lt;code&gt;Number&lt;/code&gt; type trees above, I can see that this overload can cover JSON numbers and booleans:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function visit(obj ::Real, io ::IO)
    print(io, obj)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This overload will kick in for any &lt;tt&gt;obj&lt;/tt&gt; that belongs to a type derived from &lt;code&gt;Real&lt;/code&gt; &amp;ndash; because that is more &lt;em&gt;specific&lt;/em&gt; than &lt;code&gt;Any&lt;/code&gt; and because Julia dispatch algorithm will always choose the most specific method signature to call in every situation.&lt;/p&gt;

&lt;p&gt;Strings are equally easy, but the method body needs to quote them&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:Note-that-this-t&#34;&gt;&lt;a href=&#34;#fn:Note-that-this-t&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;, so I need a new method overload:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function visit(obj ::AbstractString, io ::IO)
    print(io, &#39;&amp;quot;&#39;)
    print(io, obj)
    print(io, &#39;&amp;quot;&#39;)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So far, I have told Julia to &lt;em&gt;dispatch&lt;/em&gt; execution to either &lt;code&gt;Real&lt;/code&gt; (and its subtypes, which include ints, floats, and booleans) or &lt;code&gt;AbstractString&lt;/code&gt; (and its subtypes, including &lt;code&gt;String&lt;/code&gt; and everything that is string-like).&lt;/p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;By the way, the actual dispatch decision is based on &lt;tt&gt;(obj,&amp;nbsp;io)&lt;/tt&gt; but &lt;tt&gt;io&lt;/tt&gt; happens to be the same across all &lt;tt&gt;visit()&lt;/tt&gt;s, so the dispatch is effectively on a &lt;em&gt;single&lt;/em&gt; argument &lt;tt&gt;obj&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;Why do I suggest thinking of &lt;tt&gt;visit()&lt;/tt&gt; as &amp;ldquo;virtual&amp;rdquo;? Think of &lt;tt&gt;visit(obj,&amp;hellip;)&lt;/tt&gt; as equivalent to &lt;tt&gt;obj.visit(&amp;hellip;)&lt;/tt&gt; in a language like Python, Java, C++, where the version of &lt;tt&gt;visit()&lt;/tt&gt; to use depends on the &lt;em&gt;runtime&lt;/em&gt; type of &lt;tt&gt;obj&lt;/tt&gt;.&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Also note how abstract parent types come in handy: I don&amp;rsquo;t need to code explicit &lt;tt&gt;visit(Float32,&amp;hellip;)&lt;/tt&gt;, &lt;tt&gt;visit(Float64,&amp;hellip;)&lt;/tt&gt;, &lt;tt&gt;visit(BigFloat,&amp;hellip;)&lt;/tt&gt; for all possible (and future!) leaves of the type tree because I can handle things at the level of abstract parent nodes.&lt;/p&gt;

&lt;p&gt;By this point, my imlementation roadmap should be apparent: I am going to keep adding more &lt;tt&gt;visit()&lt;/tt&gt; overloads with &lt;tt&gt;obj&lt;/tt&gt; parameter types chosen so as to partition the type universe into subtrees that correctly &amp;ldquo;carve out&amp;rdquo; each supported type of anything I expect to find inside my input. Taking the next step, for objects that can contain other objects the virtual nature of &lt;tt&gt;visit()&lt;/tt&gt; becomes critical:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function visit(obj ::AbstractArray, io ::IO)
    print(io, &#39;[&#39;)
    for i in 1 : length(obj)
        i &amp;gt; 1 &amp;amp;&amp;amp; print(io, &amp;quot;, &amp;quot;)
        visit(obj[i], io)
    end
    print(io, &#39;]&#39;)
end

function visit(obj ::AbstractDict, io ::IO)
    print(io, &#39;{&#39;)
    first = true
    for (k, v) in obj
        first ? first = false : print(io, &amp;quot;, &amp;quot;)
        visit(k ::AbstractString, io) # assert that key is a string
        print(io, &amp;quot; : &amp;quot;)
        visit(v, io)
    end
    print(io, &#39;}&#39;)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The nested &lt;tt&gt;visit()&lt;/tt&gt;s are already virtual, nothing else needs to be done to pick up a particular overload. There are also no &amp;ldquo;if-obj-type-is-&amp;hellip;&amp;rdquo; condition checks &amp;ndash; everything is as clean as in &amp;ldquo;pure&amp;rdquo; textbook OOP.&lt;/p&gt;

&lt;p&gt;Just a handful of lines of code so far, and yet they already work on a variety of inputs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; to_JSON(stdout, [1, false, zeros(2), [1.2345, 12, Dict(&amp;quot;a&amp;quot; =&amp;gt; true, &amp;quot;b&amp;quot; =&amp;gt; 2.3, &amp;quot;c&amp;quot; =&amp;gt; [1, 2, 3.4])]])
[1, false, [0.0, 0.0], [1.2345, 12, {&amp;quot;c&amp;quot; : [1.0, 2.0, 3.4], &amp;quot;b&amp;quot; : 2.3, &amp;quot;a&amp;quot; : true}]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not bad, looks like valid JSON to me.&lt;/p&gt;

&lt;p&gt;Now, suppose that I would like to extend the set of supported &amp;ldquo;JSON-compatible&amp;rdquo; Julia types to also include tuples. I would like to output them as JSON arrays. All I need to do is add another overload:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia&#34;&gt;function visit(obj ::Tuple, io ::IO)
    print(io, &#39;[&#39;)
    for i in 1 : length(obj)
        i &amp;gt; 1 &amp;amp;&amp;amp; print(io, &amp;quot;, &amp;quot;)
        visit(obj[i], io)
    end
    print(io, &#39;]&#39;)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-julia-repl&#34;&gt;julia&amp;gt; to_JSON(stdout, [(&amp;quot;tuple&amp;quot;, (1, &amp;quot;nested&amp;quot;, &amp;quot;tuple&amp;quot;))  1, false, zeros(2), [1.2345, 12, Dict(&amp;quot;a&amp;quot; =&amp;gt; true, &amp;quot;b&amp;quot; =&amp;gt; 2.3, &amp;quot;c&amp;quot; =&amp;gt; [1, 2, 3.4])]])
[[&amp;quot;tuple&amp;quot;, [1, &amp;quot;nested&amp;quot;, &amp;quot;tuple&amp;quot;]], 1, false, [0.0, 0.0], [1.2345, 12, {&amp;quot;c&amp;quot; : [1.0, 2.0, 3.4], &amp;quot;b&amp;quot; : 2.3, &amp;quot;a&amp;quot; : true}]]
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Observe how no earlier &lt;tt&gt;visit()&lt;/tt&gt;s needed to be modified to become &amp;ldquo;aware&amp;rdquo; of this new support for tuples. In other words, a method added &lt;em&gt;later&lt;/em&gt; hooks into a set of mutual method invocations coded &lt;em&gt;earlier&lt;/em&gt;, with no ostensible &amp;ldquo;recompilation&amp;rdquo;.
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;If you&amp;rsquo;re interested in playing with various design alternatives yourself, you can find this entire example &lt;a href=&#34;https://github.com/vladium/study_julia_with_me/tree/master/type_annotations/Tutorial.jl&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In summary, I would like to call out some things about Julia typing that make Julia feel different from many languages:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Julia supports user-definable primitive types which do not need to be &amp;ldquo;boxed&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;All superclasses are abstract and all concrete classes are final.&lt;/li&gt;
&lt;li&gt;Mutability is part of type definition, not of argument/variable/field.&lt;/li&gt;
&lt;li&gt;Multiple dispatch is a primary paradigm (&amp;ldquo;all methods are virtual&amp;rdquo;). This design is consistent with lack of classic &amp;ldquo;objects&amp;rdquo; that forcefully bundle state with behavior.&lt;/li&gt;
&lt;li&gt;Duck-typing also works in Julia, perhaps even without any performance loss. But certain core Julia features necessitate some static typing.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:This-is-what-the&#34;&gt;This is what the public documentation says. Examining &lt;tt&gt;boot.jl&lt;/tt&gt; of my Julia install shows that many of these types are actually implemented in C. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:This-is-what-the&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:As-I-write-this&#34;&gt;As I write this, bit widths must be multiples of 8. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:As-I-write-this&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:Just-like-classe&#34;&gt;Just like classes marked with &lt;code&gt;final&lt;/code&gt; keyword in C++ or Java. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:Just-like-classe&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:I-use-an-extra-b&#34;&gt;I use an extra blank before &lt;code&gt;::&lt;/code&gt; but you don&amp;rsquo;t have to. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:I-use-an-extra-b&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:To-simply-the-na&#34;&gt;To simply the narrative, I am glossing over possibilities for &lt;em&gt;promotion&lt;/em&gt; of &lt;code&gt;x&lt;/code&gt; to another type. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:To-simply-the-na&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:From-what-I-can&#34;&gt;From what I can tell so far, that is. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:From-what-I-can&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:Note-that-this-t&#34;&gt;Note that this toy serializer doesn&amp;rsquo;t bother with backslash escapes, Unicode, etc. &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:Note-that-this-t&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Automatic differentiation from scratch, in 10 lines of Julia</title>
      <link>/tutorials/study_julia_with_me/multiple_dispatch/</link>
      <pubDate>Sun, 27 Oct 2019 00:00:00 +0000</pubDate>
      <guid>/tutorials/study_julia_with_me/multiple_dispatch/</guid>
      <description>


&lt;p&gt;I mentioned Julia’s fondness for multiple dispatch in my &lt;a href=&#34;../type_annotations/&#34;&gt;first typing tutorial&lt;/a&gt;. On purpose at the time, my case study was limited to the simplest case: single dispatch. I’ve waited until I ran across an example of a “natural”&#34; problem where multiple dispatch would play an important role. I think I’ve found one: differentiating a function with no closed-form formula.&lt;/p&gt;
&lt;div id=&#34;preview&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Preview&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Play with a custom number-like type.&lt;/li&gt;
&lt;li&gt;Simplify implementation by leveraging Julia’s support for type promotions.&lt;/li&gt;
&lt;li&gt;Review (very quickly) one technique for automated differentiation (AD).&lt;/li&gt;
&lt;li&gt;Implement Forward AD through operator overloading. Test it in several ways, finish by plugging it into a Newton-Raphson solver.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;differentiate-this&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Differentiate this&lt;/h1&gt;
&lt;p&gt;To set my overall objective, I would like to be able to compute the derivative of the following function:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function myerf(x ::Number)
    Σ = 0.0
    x² = x * x
    for k in 0 : 20 # hardcoding the number of summation terms for simplicity
        Σ += x / (factorial(k) * (2k + 1))
        x *= -x²
    end
    return 2.0 / √π * Σ
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This just sums a truncated Taylor series for &lt;a href=&#34;https://en.wikipedia.org/wiki/Error_function&#34;&gt;erf(x)&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\text{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{-\infty}^{x}e^{-t^2}dt = \frac{2}{\sqrt{\pi}} \sum_{k=0}^{\infty} \frac{(-1)^k x^{2k+1}}{k! (2k+1)}
\]&lt;/span&gt;
This series is straightforward to derive by integrating the one for &lt;span class=&#34;math inline&#34;&gt;\(e^{-x^2}\)&lt;/span&gt;. That fact will also allow me to easily check my derivative function, when I get one, against the known correct answer&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial x} \text{erf}(x) = \frac{2}{\sqrt{\pi}} e^{-x^2}
\]&lt;/span&gt;
My sum-of-the-series implementation seems correct&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;# if you haven&amp;#39;t installed SpecialFunctions yet:
# pkg&amp;gt; add SpecialFunctions
julia&amp;gt;using SpecialFunctions # for the &amp;quot;official&amp;quot; erf(x)

julia&amp;gt; myerf(0.7), erf(0.7)
(0.6778011938374184, 0.6778011938374184)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, I know the closed-form expression for the derivative of &lt;tt&gt;myerf(x)&lt;/tt&gt; and somehow I need to get the computer to get it, too, but without actually entering the closed-form answer. And, by the way, I would like a solution that’s as &lt;em&gt;exact&lt;/em&gt; as possible, something not based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives&#34;&gt;finite differences&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;baby-julia-steps-operators-functions-and-methods&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Baby Julia steps: operators, functions, and methods&lt;/h1&gt;
&lt;p&gt;To understand the AD example that’s coming up, it will be helpful to delve a little bit into Julia’s model of function dispatch and evaluation. It may seem like an unnecessarily long detour but I promise it will all come together and the learnings will be general.&lt;/p&gt;
&lt;p&gt;For the following one-line function definition&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; g(x) = x * (x + x)
g (generic function with 1 method)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;consider how the inputs (of which &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; has only one, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;) determine its eventual value&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;: we sum two copies of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, then multiply that intermediate result by another &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. You could say that all these values, both the inputs and the intermediates, &lt;em&gt;propagate&lt;/em&gt; through &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;’s &lt;em&gt;calculation graph&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;g_graph.png&#34; style=&#34;width:35.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each function call node in such a graph is an elementary step of the calculation. In fact, I can drill into these steps directly from Julia:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; g_tree = :(x * (x + x)) # &amp;#39;:(...)&amp;#39; is the &amp;quot;quoting&amp;quot; operator here: it parses what&amp;#39;s inside into a syntax tree
:(x * (x + x))

julia&amp;gt; typeof(g_tree)
Expr

julia&amp;gt; dump(g_tree) # show g_tree as a tree of annotated nodes
Expr
  head: Symbol call
  args: Array{Any}((3,))
    1: Symbol *
    2: Symbol x
    3: Expr
      head: Symbol call
      args: Array{Any}((3,))
        1: Symbol +
        2: Symbol x
        3: Symbol x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What &lt;code&gt;dump()&lt;/code&gt; shows is a tree of expression (&lt;code&gt;Expr&lt;/code&gt;) nodes comprising the calculation graph for &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt;. Each node annotated with &lt;code&gt;Symbol call&lt;/code&gt; is an invocation of one elementary step like multiplication (&lt;code&gt;*&lt;/code&gt;), addition (&lt;code&gt;+&lt;/code&gt;), and so on – those were the diamond-shaped nodes in the picture. (If you have some CS background or ever worked on an interpreter or compiler, this ground should feel very familiar.)&lt;/p&gt;
&lt;div id=&#34;julia-operators-are-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Julia operators are functions&lt;/h2&gt;
&lt;p&gt;As already implied by the syntax tree form of &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt;, almost&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; all elementary operators like &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;+&lt;/code&gt;, etc are actually Julia functions with special infix syntax. They are defined as such and can be invoked with the “normal” function call syntax:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; x = 2;

julia&amp;gt; x + x
4

julia&amp;gt; +(x, x) # call function named &amp;quot;+&amp;quot; with parameter tuple &amp;quot;(x, x)&amp;quot;
4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(In fact, most of Julia is defined via its own syntax, something the language designers and user community are justifiably proud of.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;julia-functions-are-overloadable-or-is-it-overridable-smile&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Julia functions are “overloadable” (or is it “overridable”? 😄)&lt;/h2&gt;
&lt;p&gt;Multiplying two integers is not the same as “multiplying” two strings&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; x * x
4

julia&amp;gt; &amp;quot;x&amp;quot; * &amp;quot;x&amp;quot;
&amp;quot;xx&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and might be different from “multiplying” objects of a user-defined type. As I started to explain in my &lt;a href=&#34;../type_annotations/#case-study-functional-oop&#34;&gt;previous typing tutorial&lt;/a&gt;, this is made possible by using different parameter types for different function versions (“methods”, in Julia parlance). Internally, Julia keeps a list of all methods it is aware of for each operator/function and they can be examined using &lt;a href=&#34;https://docs.julialang.org/en/v1/base/base/#Base.methods&#34;&gt;methods()&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; methods(*)
# 358 methods for generic function &amp;quot;*&amp;quot;:
[1] *(x::Bool, z::Complex{Bool}) in Base at complex.jl:282
[2] *(x::Bool, y::Bool) in Base at bool.jl:98
[3] *(x::Bool, y::T) where T&amp;lt;:AbstractFloat in Base at bool.jl:110
[4] *(x::Bool, z::Complex) in Base at complex.jl:289
[5] *(x::Bool, y::AbstractIrrational) in Base at irrationals.jl:139
[6] *(a::Float16, b::Float16) in Base at float.jl:392
[7] *(x::Float32, y::Float32) in Base at float.jl:398
[8] *(x::Float64, y::Float64) in Base at float.jl:399
[9] *(z::Complex{Bool}, x::Bool) in Base at complex.jl:283
... lots more ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is possible for a user to add more methods to such lists. Each row has a unique signature. Imagine defining your own “numbers”:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; struct MyNum &amp;lt;: Number
           v   ::Float64
       end

julia&amp;gt; MyNum(2.0) * MyNum(2.0) # this won&amp;#39;t work
ERROR: MethodError: no method matching *(::MyNum, ::MyNum)
Closest candidates are:
  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:529

julia&amp;gt; Base.:(*)(lhs ::MyNum, rhs ::MyNum) = MyNum(lhs.v * rhs.v) # define &amp;#39;MyNum * MyNum&amp;#39;, so now it will

julia&amp;gt; MyNum(2.0) * MyNum(2.0)
MyNum(4.0)

julia&amp;gt; methods(MyNum)
# 2 methods for generic function &amp;quot;(::Type)&amp;quot;:
[1] MyNum(v::Float64) in Main at none:1
[2] MyNum(v) in Main at none:1

julia&amp;gt; methods(*)
# 359 methods for generic function &amp;quot;*&amp;quot;: # &amp;lt;- note that count is up by one
[1] *(x::Bool, z::Complex{Bool}) in Base at complex.jl:282
...
[31] *(lhs::MyNum, rhs::MyNum) in Main at none:1
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note again how the new method doesn’t “belong” to &lt;code&gt;MyNum&lt;/code&gt; but rather to a global &lt;a href=&#34;https://docs.julialang.org/en/v1/devdocs/functions/#Method-Tables-1&#34;&gt;method table&lt;/a&gt; associated with &lt;code&gt;*&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Continuing, I would need to define a minimal collection of arithmetic operations in order for `MyNum’s to be useful as something resembling numbers:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;# binary ops:

Base.:(+)(lhs ::MyNum, rhs ::MyNum) = MyNum(lhs.v + rhs.v)
Base.:(-)(lhs ::MyNum, rhs ::MyNum) = MyNum(lhs.v - rhs.v)

Base.:(*)(lhs ::MyNum, rhs ::MyNum) = MyNum(lhs.v * rhs.v)
Base.:(/)(lhs ::MyNum, rhs ::MyNum) = MyNum(lhs.v / rhs.v)

# unary ops:

Base.:(+)(x ::MyNum) = x
Base.:(-)(x ::MyNum) = MyNum(- x.v)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; MyNum(3.0) + MyNum(4.0)
MyNum(7.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far, so good. Note that &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt; is generic enough so it “just works” for both plain floats &lt;em&gt;and&lt;/em&gt; &lt;code&gt;MyNum&lt;/code&gt;s:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; g(2.0)
8.0

julia&amp;gt; g(MyNum(2.0))
MyNum(8.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Take note, this will happen again later. Of course, &lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt; is downright trivial: it uses only &lt;code&gt;*&lt;/code&gt; and &lt;code&gt;+&lt;/code&gt; – this was truly a baby step.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;something-is-missing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Something is missing&lt;/h2&gt;
&lt;p&gt;My custom, soon-to-win-many-awards, number type is missing some boilerplate stuff. Trying another simple function fails; it flat out refuses to work with &lt;code&gt;MyNum&lt;/code&gt;s:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; f(x) = 1.0 / x
f (generic function with 1 method)

julia&amp;gt; f(MyNum(2.0))
ERROR: promotion of types Float64 and MyNum failed to change any arguments
Stacktrace:
 [1] sametype_error(::Tuple{Float64,MyNum}) at ./promotion.jl:308
 [2] not_sametype(::Tuple{Float64,MyNum}, ::Tuple{Float64,MyNum}) at ./promotion.jl:302
 [3] promote at ./promotion.jl:285 [inlined]
 [4] /(::Float64, ::MyNum) at ./promotion.jl:316
 [5] f(::MyNum) at ./none:1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I can see from the stacktrace that &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; was indeed found and started, but something went wrong later: there was no suitable defition of &lt;code&gt;/&lt;/code&gt; for parameter type pair (&lt;code&gt;Float64&lt;/code&gt;, &lt;code&gt;MyNum&lt;/code&gt;). Julia does not know to convert the &lt;tt&gt;1.0&lt;/tt&gt; in &lt;code&gt;1.0 / x&lt;/code&gt; to a &lt;code&gt;MyNum&lt;/code&gt; – the language does not have what’s called &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/conversion-and-promotion/&#34;&gt;&lt;em&gt;automatic&lt;/em&gt; promotion&lt;/a&gt;. As a result, &lt;code&gt;MyNum&lt;/code&gt;s don’t interoperate with the “stock” numbers particularly well.&lt;/p&gt;
&lt;div id=&#34;promotion-fix-1-moar-dispatch&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Promotion fix #1: MOAR dispatch!&lt;/h3&gt;
&lt;p&gt;One way to proceed is to keep adding to the method table for &lt;code&gt;/&lt;/code&gt; (and other ops) until all conceivable cases are covered:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; Base.:(/)(lhs ::Float64, rhs ::MyNum) = MyNum(lhs / rhs.v) # float / MyNum

julia&amp;gt; f(MyNum(2.0)) # f() works now
MyNum(0.5)

julia&amp;gt; h(x) = x / 3.0
h (generic function with 1 method)

julia&amp;gt; h(MyNum(2.0))
ERROR: promotion of types MyNum and Float64 failed to change any arguments
...

julia&amp;gt; Base.:(/)(lhs ::MyNum, rhs ::Float64) = MyNum(lhs.v / rhs) # MyNum / float

julia&amp;gt; h(MyNum(2.0)) # h() works now, too
MyNum(0.6666666666666666)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, &lt;em&gt;all possible permutations&lt;/em&gt; of parameter types need to be implemented by &lt;em&gt;all&lt;/em&gt; operators. This game of whack-a-mole seems laborious and error-prone. Hmm, is it possible to have &lt;em&gt;too much&lt;/em&gt; dispatch? 😄&lt;/p&gt;
&lt;p&gt;This design choice begs for some automatic code generation and indeed I think it can be made viable through Julia’s &lt;em&gt;metaprogramming&lt;/em&gt; facilities, specifically &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/metaprogramming/#man-macros-1&#34;&gt;macros&lt;/a&gt;. But because I haven’t covered metaprogramming yet, I will instead go another, easier for the time being, route.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;promotion-fix-2-promote_rule&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Promotion fix #2: &lt;strong&gt;promote_rule()&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Julia has &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/conversion-and-promotion/#Promotion-1&#34;&gt;provisions for dealing with the explosion in the number of needed permutations of argument types&lt;/a&gt;. The idea is as follows: instead of expecting for there to be an &lt;tt&gt;op(T1, T2)&lt;/tt&gt; method for every possible &lt;tt&gt;(T1, T2)&lt;/tt&gt; pair, a collection of “promotion rules” is queried to find out whether &lt;tt&gt;T1&lt;/tt&gt; and &lt;tt&gt;T2&lt;/tt&gt; can be first converted to a &lt;em&gt;common&lt;/em&gt; type &lt;tt&gt;T&lt;/tt&gt; (which could be, but doesn’t have to be, either &lt;tt&gt;T1&lt;/tt&gt; or &lt;tt&gt;T2&lt;/tt&gt;). If that is possible, it is assumed that the conversion is lossless and subsequently only the &lt;tt&gt;op(T, T)&lt;/tt&gt; overload will be needed.&lt;/p&gt;
&lt;p&gt;It is easy to see how this system reduces the need for very large method tables. In the case of &lt;code&gt;MyNum&lt;/code&gt;, the correct incantation is:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;Base.promote_rule(::Type{MyNum}, ::Type{&amp;lt;: Number}) = MyNum&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which specifies that whenever a mix of &lt;code&gt;MyNum&lt;/code&gt; and subtype-of-&lt;code&gt;Number&lt;/code&gt; is encountered, the common type &lt;tt&gt;T&lt;/tt&gt; to use is &lt;code&gt;MyNum&lt;/code&gt;. This is less “automatic”, but it works. This way Julia supports type promotions that in other languages like C++ and Java are done by the compiler (and hence are fairly fixed).&lt;/p&gt;
&lt;p&gt;So now a much more compact and yet robust arithmetic system for a custom number type can be implemented with two types of building blocks:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;actual arithmetic/math operators and functions, defined to take &lt;em&gt;only&lt;/em&gt; the custom number arguments;&lt;/li&gt;
&lt;li&gt;if needed, promotion rules to make the custom types interoperate with the “stock” types.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is the design I use below as part of my demo AD implementation. You can read the handful of lines needed to have custom arithmetic operations in the &lt;a href=&#34;https://github.com/vladium/study_julia_with_me/tree/master/multiple_dispatch/FAD.jl&#34;&gt;supporting module file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Whew! 😰 It took a bit longer than I thought, but the language mechanics have been explained and I can return to my original objective: fun with differentiating stuff in Julia.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;case-study-automatic-differentiation-via-forward-prop&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Case study: automatic differentiation via “forward prop”&lt;/h1&gt;
&lt;p&gt;What I need now is some &lt;a href=&#34;https://en.wikipedia.org/wiki/Automatic_differentiation&#34;&gt;Automatic Differentiation (AD)&lt;/a&gt;. There are many AD flavors but I will exlore just one simple variant called “forward” (also “tangent” or “standard”) AD. Forward AD is particularly easy to engineer in a language that offers operator overloading, which we now understand Julia does. (By the way, if you search the web chances are you will run into tutorials that introduce Forward AD via &lt;a href=&#34;https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers&#34;&gt;dual numbers&lt;/a&gt; – I do not do that here because I don’t think it is particularly intuition-inducing.)&lt;/p&gt;
&lt;p&gt;You may have noted that &lt;tt&gt;myerf(x)&lt;/tt&gt; was coded in a profoundly “non-functional” style: it has evil procedural things like variable mutation in a &lt;tt&gt;for&lt;/tt&gt;-loop. Nevertheless, AD can work with it&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; and I believe that to be a simple example of &lt;a href=&#34;https://sinews.siam.org/Details-Page/scientific-machine-learning-how-julia-employs-differentiable-programming-to-do-it-best&#34;&gt;&lt;em&gt;differentiable programming&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;strong&gt;Core AD ideas:&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A calculation is a &lt;em&gt;composition&lt;/em&gt; of smaller steps&lt;/li&gt;
&lt;li&gt;These steps can be &lt;em&gt;instrumented&lt;/em&gt; to generate “stuff” &lt;em&gt;in addition&lt;/em&gt; to the original expression values.
  &lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;core-ad-idea-1-composition-of-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Core AD idea #1: composition of steps&lt;/h2&gt;
&lt;p&gt;If you’ve made it through the preceeding sections, the following should now be seared into your subconscious: a function computes its output by forward-propagating inputs and intermediate expression values through its calculation graph. These elementary steps are &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt;, &lt;code&gt;cos&lt;/code&gt;, &lt;code&gt;sin&lt;/code&gt;, etc.&lt;/p&gt;
&lt;p&gt;Futhermore, these steps are not very “intrinsic” or somehow untouchable: I’ve shown that I could wrap values into a custom type and overload all the operations I am interested in. This works beacuse of Julia’s core paradigm of (multiple) dispatch on argument types.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;core-ad-idea-2-step-instrumentation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Core AD idea #2: step instrumentation&lt;/h2&gt;
&lt;p&gt;Just one more step remaining. Why did I bother replicating standard arithmetic with &lt;code&gt;MyNum&lt;/code&gt;? Sure, it was to understand better how some aspects of Julia worked. But note this: computing the derivative of a function is also a &lt;em&gt;composable&lt;/em&gt; calculation and &lt;em&gt;it can be done in parallel with computing the function value&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;So… if I extend &lt;code&gt;MyNum&lt;/code&gt; with another field to hold the current expression’s &lt;em&gt;derivative&lt;/em&gt;, I can forward-propagate it in the same pass as the main&#34; value:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;struct Context &amp;lt;: Number
    v   ::Float64
    ∂   ::Float64
end&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;# binary ops:

Base.:(+)(lhs ::Context, rhs ::Context) = Context(lhs.v + rhs.v, lhs.∂ + rhs.∂)
Base.:(-)(lhs ::Context, rhs ::Context) = Context(lhs.v - rhs.v, lhs.∂ - rhs.∂)

Base.:(*)(lhs ::Context, rhs ::Context) = Context(lhs.v * rhs.v, lhs.v * rhs.∂ + lhs.∂ * rhs.v)
Base.:(/)(lhs ::Context, rhs ::Context) = Context(lhs.v / rhs.v, (lhs.∂ * rhs.v - lhs.v * rhs.∂) / rhs.v^2)

# unary ops:

Base.:(+)(x ::Context) = x
Base.:(-)(x ::Context) = Context(- x.v, - x.∂)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &lt;code&gt;Context&lt;/code&gt; is the grown-up version of &lt;code&gt;MyNum&lt;/code&gt;. It has been extended with field &lt;span class=&#34;math inline&#34;&gt;\(\partial\)&lt;/span&gt;. The arithmetic overloads for &lt;code&gt;Context&lt;/code&gt; continue to propagate &lt;em&gt;expression values&lt;/em&gt; in &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; while some new logic propagates &lt;em&gt;derivative values&lt;/em&gt; in &lt;span class=&#34;math inline&#34;&gt;\(\partial\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Individual &lt;code&gt;Context&lt;/code&gt; &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;-rules are composed to form a larger calculation such as &lt;tt&gt;myerf(x)&lt;/tt&gt;. Consistently with such pattern of composition, each &lt;span class=&#34;math inline&#34;&gt;\(\partial\)&lt;/span&gt;-rule can be seen to be an application of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Chain_rule&#34;&gt;chain rule&lt;/a&gt; for obtaining derivatives of the composition of functions. For example, since
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial x} (lhs + rhs)(x) = \frac{\partial}{\partial x} lhs(x) + \frac{\partial}{\partial x} rhs(x)
\]&lt;/span&gt;
the &lt;code&gt;Context&lt;/code&gt; rule for &lt;code&gt;+&lt;/code&gt; must be
&lt;span class=&#34;math display&#34;&gt;\[
+\big( \langle lhs.v, lhs.\partial \rangle, \langle rhs.v, rhs.\partial \rangle \big) = \big\langle (lhs.v + rhs.v), (lhs.\partial + rhs.\partial) \big\rangle.
\]&lt;/span&gt;
The rule for &lt;code&gt;sin&lt;/code&gt;, should it be needed, would be
&lt;span class=&#34;math display&#34;&gt;\[
\sin \big(\langle x.v, x.\partial \rangle \big) = \big\langle \sin(x.v), \cos(x.v) \partial \big\rangle,
\]&lt;/span&gt;
and so on.&lt;/p&gt;
&lt;p&gt;What &lt;code&gt;Context&lt;/code&gt; value should be fed as the initial input? It’s &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt;-field is &lt;tt&gt;x&lt;/tt&gt;. The derivative of that with respect to &lt;tt&gt;x&lt;/tt&gt; is 1.0, so to establish derivative propagation correctly it needs to be seeded with &lt;code&gt;Context(x, 1.0)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;And that’s pretty much it. Does it work? Let’s give it a try:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function derivative(f ::Function)
    return x ::Number -&amp;gt; f(Context(x, 1.0)).∂ # discard value, return derivative
end

∂ = derivative # add a nice-looking alias&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the moment of truth:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; include(&amp;quot;multiple_dispatch/FAD.jl&amp;quot;)
Main.FAD

julia&amp;gt; using Main.FAD # bring ∂, etc into this REPL

julia&amp;gt; x = 0.7;

julia&amp;gt; ∂(myerf)(x), 2/√π * exp(-x^2)
(0.6912748604105389, 0.6912748604105386)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Success!&lt;/p&gt;
&lt;p&gt;&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;Observe something neat: myerf(x) hasn’t stopped working for plain float x’s – it is still &lt;em&gt;generic&lt;/em&gt;. Invoked with a scalar float x, it will return just the erf(x) value and spend no CPU cycles computing anything else. Invoked with a &lt;code&gt;Context&lt;/code&gt;, it will return both erf(x) and its derivative at x. Of course, two different bits of native assembly execute in these two cases. Both versions (that is, &lt;em&gt;methods&lt;/em&gt; of a function named “myerf”) will be JIT’ed separately.&lt;/p&gt;
&lt;p&gt;myerf(Context) is in fact a version of myerf(x) &lt;strong&gt;instrumented&lt;/strong&gt; to carry out additional calculations and carry additional, well, &lt;em&gt;context&lt;/em&gt; through the calculation graph that defines myerf(x).&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;As a different test, the chain rule &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial}{\partial x}(f \circ g)(x) = \frac{\partial}{\partial g} f(g(x)) \frac{\partial}{\partial x} g(x)\)&lt;/span&gt; should also hold for arbitrary “differentiable” Julia functions:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; f(x) = 1.0 / x
f (generic function with 1 method)

julia&amp;gt; g(x) = x * (x + x)
g (generic function with 1 method)

julia&amp;gt; x = 1.2345;

julia&amp;gt; ∂(f ∘ g)(x), ∂(f)(g(x)) * ∂(g)(x)
(-0.5315286974115385, -0.5315286974115385)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think this is downright &lt;em&gt;beautiful&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;And last but not least, let me try an algorithm that can benefit from having both &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\frac{\partial}{\partial x}f(x)\)&lt;/span&gt; available at the same time, e.g. &lt;a href=&#34;https://en.wikipedia.org/wiki/Newton%27s_method&#34;&gt;Newton-Raphons root finder&lt;/a&gt;. Here is a prototype version performing &lt;span class=&#34;math inline&#34;&gt;\(x_{n+1} = x_n - \frac{f(x_n)}{\frac{\partial}{\partial x}f(x_n)}\)&lt;/span&gt; iterations until convergence within given tolerance:&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;function root_solve(f ::Function, x₀ ::Number; ϵ = 1e-8)
    i = 1
    while true
        ctx = f(Context(x₀, 1.0))
        println(&amp;quot;[$i]: f($x₀)\t= $(ctx.v)&amp;quot;)
        abs(ctx.v) &amp;lt; ϵ &amp;amp;&amp;amp; break
        x₀ -= ctx.v / ctx.∂ # use both value and derivative
        i += 1
    end
    return x₀
end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I extend my &lt;code&gt;Context&lt;/code&gt; “algebra” with some more elementary operations&lt;/p&gt;
&lt;pre class=&#34;julia&#34;&gt;&lt;code&gt;Base.sin(d ::Context) = Context(sin(d.v),   cos(d.v) * d.∂)
Base.cos(d ::Context) = Context(cos(d.v), - sin(d.v) * d.∂)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then I can try solving, say, trigonometric equations:&lt;/p&gt;
&lt;pre class=&#34;julia-repl&#34;&gt;&lt;code&gt;julia&amp;gt; root_solve(x -&amp;gt; sin(x) - cos(x), 0.0) # find a root of sin(x) = cos(x) starting from x₀ = 0
[1]: f(0.0) = -1.0
[2]: f(1.0) = 0.30116867893975674
[3]: f(0.782041901539138)   = -0.004746462127804163
[4]: f(0.7853981759997019)  = 1.7822277875723103e-8
[5]: f(0.7853981633974483)  = -1.1102230246251565e-16
0.7853981633974483

julia&amp;gt; π/4
0.7853981633974483&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice. I find this all &lt;em&gt;very&lt;/em&gt; satisfying. Especially given how few lines of Julia actually went into the &lt;a href=&#34;https://github.com/vladium/study_julia_with_me/tree/master/multiple_dispatch/FAD.jl&#34;&gt;final implementation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For an industrial-strength implementation of this approach to AD, check out &lt;a href=&#34;https://github.com/JuliaDiff/ForwardDiff.jl&#34;&gt;ForwardDiff.jl&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;I am abusing the partial derivative symbol &lt;span class=&#34;math inline&#34;&gt;\(\partial\)&lt;/span&gt; for all my derivative notation here, including Julia code.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;My implementation ignores possible overflows in &lt;tt&gt;x²&lt;/tt&gt;, &lt;tt&gt;factorial(k)&lt;/tt&gt;, etc – it is intentionally made to evoke the symbolic series expression. A.k.a. “research code”.😄 &lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;The compiler may choose to optimize this subexpression to &lt;span class=&#34;math inline&#34;&gt;\(2x\)&lt;/span&gt; but that doesn’t invalidate the forgoing.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;There are exceptions like &lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt; and &lt;code&gt;||&lt;/code&gt; because those obey &lt;a href=&#34;https://docs.julialang.org/en/v1/manual/control-flow/#Short-Circuit-Evaluation-1&#34;&gt;short-circuit evaluation rules&lt;/a&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;Yes, Julia uses &lt;code&gt;*&lt;/code&gt; for string concatenation. A little unorthodox?&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;Although in general AD isn’t guaranteed to work with &lt;em&gt;all&lt;/em&gt; such functions.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
