[{"authors":["admin"],"categories":null,"content":"Vlad Roubtsov works on stochastic and simulation-based optimization problems at a large retailer. He leverages his cross-disciplinary background (physics, math, computer science) to bridge quantitative research with software development.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"258be61fc6f4ec5204c804c5b2f71116","permalink":"/authors/vlad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/vlad/","section":"authors","summary":"Vlad Roubtsov works on stochastic and simulation-based optimization problems at a large retailer. He leverages his cross-disciplinary background (physics, math, computer science) to bridge quantitative research with software development.","tags":null,"title":"Vlad Roubtsov","type":"authors"},{"authors":null,"categories":null,"content":" Introduction and welcome Greetings! I work on stochastic optimization and simulation problems and happen to have extensive background in both \u0026ldquo;high productivity\u0026rdquo; and \u0026ldquo;high performance\u0026rdquo; programming languages. I had my first peek at Julia a few years ago. The concept was great and the new language certainly had a real, uncrowded niche to fit in: something that promised to be both high productivity and high performance. But right then it was brand new and the ecosystem just didn\u0026rsquo;t feel organized or stable enough for \u0026ldquo;production use\u0026rdquo;.\nA few years later, Julia v1.0 milestone has been achieved, there is an IDE or two, university classes are abandoning MATLAB/octave in favor of Julia, and new Julia books are coming out with increasing frequency. Now it appears to me that Julia is much more mature and ready for another, more thorough, examination. For this reason, I invite you to take part in this study group.\nPurpose What do we plan to get out of this study? A couple of things, at least:\n Julia does not look like a radically new programming language to me. Rather, it appears to combine many of the best and most modern aspects of language design in order to support productive scientific programming. I would us like to understand the main paradigms in Julia so that we can judge where and when it would be the most effective choice for research work.\n As a component of overall productivity, I care about language performance in both interactive and parallel/distributed settings. I would like us to put Julia speed claims to the test.\n Julia is still quite new (v1.0 just shipped in 2018) and good study material is a little hard to come by. We could look at some existing open-source tools for operations research and machine learning as examples of working Julia projects, and perhaps prototype a few of our own in the process.\n  Study agenda (open to feedback) At a high level, these are the topics I\u0026rsquo;d like us to cover (not necessarily in the order shown and subject to feedback and suggestions from the group):\n language design and capabilities: core types, generic functions/multiple dispatch, metaprogramming, parallel/distributed programming, etc. general purpose tooling: IDE, plotting, debugging, profiling, etc. native support and tools for OR, ML, and statistics: dataframes, built-in linear algebra, JuMP, JuML, etc.  Each week I would us like to formulate a practical question or need and investigate a solution (or lack thereof) within the Julia ecosystem, at which point I will document it here. Some example questions off the top of my head are:\n What\u0026rsquo;s this I hear about Julia being \u0026ldquo;fast\u0026rdquo;? How does it compare with Python or R? How about C++? I have an optimization problem that needs a custom algorithm not covered by off-the-shelf solvers \u0026ndash; should I consider a (pure) Julia implementation? Conversely, I have a bog-standard LP model \u0026ndash; is there still an advantage to working with it in Julia? How do I develop a Julia package, or, more generally, have workflow that\u0026rsquo;s good for research that I want to share with colleagues? Julia is marketed as good for parallel computing \u0026ndash; what\u0026rsquo;s the reality of this claim? \u0026hellip; and so on, as long as there are useful topics to explore.  Prerequisites I think it would be helpful to have some experience with one or two of the languages that Julia aims to (will eventually?) replace: R, Matlab, Python, and others of that ilk. Julia also borrows from JIT\u0026rsquo;ed languages like Java, so familiarity with those can only help.\n","date":1569024000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1569024000,"objectID":"7ee0ab098699d251db43779d8f3524d3","permalink":"/tutorials/study_julia_with_me/","publishdate":"2019-09-21T00:00:00Z","relpermalink":"/tutorials/study_julia_with_me/","section":"tutorials","summary":"Ongoing study of topics from language design, operations research, and computer/data sciences.","tags":null,"title":"Study Julia with me","type":"docs"},{"authors":null,"categories":null,"content":" Suggested software setup I have been using Julia successfully on MacOS and Linux (Fedora). I would suggest starting with a JuliaPro installer for this study. I’ve kept a few notes about my install process:\n I’ve been using v1.2 so far, both REPL and Juno “IDE”.\n on MacOS you will need to have XCode tools installed, see the install guide on Linux the install guide mentions needing these libs (install via yum/dnf/apt-get/etc, I only needed to add xclip):   xclip libXScrnSaver apparently, starting with v1.2 what’s included appears to have changed: to minimize the installer size the “curated list of packages” are no longer part of the download itself. They can be installed via the usual Pgk commands. What’s different for “curated” packages is that the install will be configured to use Julia Computing’s github repo1 so that only the supposedly tested versions are available. Using Julia Computing’s repo will require authenticating to get their token. Keep this in mind if you plan to play with packages outside of their supported list.\n for REPL you can use Juno’s “REPL” tab. I find that doing so gives me experince similar to that of RStudio (a good thing):\n   if you prefer not to rely on the IDE (which is not that great right now) and use REPL (which is very functional), you can use julia binary from your JuliaPro distribution:  MacOS: /Applications/JuliaPro-\u0026lt;version\u0026gt;.app/Contents/Resources/julia/Contents/Resources/julia/bin/julia Linux: \u0026lt;install dir\u0026gt;/Julia/bin/julia    FAQs and tips for fellow Julia explorers General  if you’re working with custom types, it is recommended to keep work code in a module (which could be as simple as keeping it inside a module MyModule ... end block) even for one-off stuff: onlike, say, R or Python Julia currently does not allow updating type definitions within a session without restarting it. It seems to have gone through several iterations of addressing this workflow need, but right now re-include()ing a module seems to be what’s guaranteed to work.  there is also Revise.jl (which I haven’t tried yet) see this discussion for more color  another reason for working inside a module is because code will run faster (it will be JIT’ed sooner)   Juno Juno is basically a few packages inside Atom. It is not quite an “IDE” at this point. Visual Studio Code might be a reasonable alternative, but in my experiments VSC had trouble with Julia v1.2. Juno comes bundled with a julia build from the same entity.\n as a result of being a collection of Atom packages, some things you might want to tweak in the UI could be dispersed over multiple places. For example:  “Julia Client” package:  you may wish to choose positioning of various tabs: Workspace, Documentation, Plots, REPL, etc  “tool-bar” package:  you might want to opt for smaller icons  “tree-view” package:  “Always Open Existing”, “Auto Reveal” settings might be of interest      Books, other resources There is a constantly growing list of resources at https://julialang.org. I list below some resources that I’ve either used myself or that seemed to stand out from the rest.\nbooks about or based on Julia v1.0+:  “Think Julia: How to Think Like a Computer Scientist” by Ben Lauwens and Allen Downey.  this is the only “pure computer science” Julia book in my list.  “A Deep Introduction to Julia for Data Science and Scientific Computing” by Chris Rackauckas.  the author is very active in Julia space; this material seems very good (if you’re ok with notebooks).  “Statistics with Julia: Fundamentals for Data Science, Machine Learning and Artificial Intelligence” by Hayden Klok and Yoni Nazarathy (2019 draft PDF free from the authors).  based on a statistics course at the University of Queensland; Julia crash course in Chapter 1 and a handy “How-to” in Appendix A.  “Julia Programming for Operations Research, 2nd ed.” by Changhyun Kwon.  another Julia crash course chapter; JuMP workship.    reference docs:  “Julia 1.2 Documentation”, HTML and PDF. “Introducing Julia” Wikibook, a nice complement to the language manual.   video lectures, talks:  “Intro to Julia 1.0” by Jane Herriman of Julia Computing. Videos from JuliaCon 2019 – some good stuff, particularly by Julia creators.   online practice:  Julia Box from Julia Computing has a free plan. Julia exercism track looks like a good collection of exercises     Julia packages are maintained as git repos.↩\n   ","date":1569196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569196800,"objectID":"6ec89205fad3531788dfe071506387c4","permalink":"/tutorials/study_julia_with_me/structure/","publishdate":"2019-09-23T00:00:00Z","relpermalink":"/tutorials/study_julia_with_me/structure/","section":"tutorials","summary":"Suggested software setup I have been using Julia successfully on MacOS and Linux (Fedora). I would suggest starting with a JuliaPro installer for this study. I’ve kept a few notes about my install process:\n I’ve been using v1.2 so far, both REPL and Juno “IDE”.\n on MacOS you will need to have XCode tools installed, see the install guide on Linux the install guide mentions needing these libs (install via yum/dnf/apt-get/etc, I only needed to add xclip):   xclip libXScrnSaver apparently, starting with v1.","tags":null,"title":"","type":"docs"},{"authors":null,"categories":null,"content":" Every once in a while, you need to try an algorithm that’s “custom enough” that it must be coded directly in your “research language”. Perhaps the existing “high-performance” libs don’t support your desired variant or it’s too much setup work switching to another language just to prototype a quick one-off idea. This an instance of the “two language problem” that’s been the reality of technical computing for decades.\nUsers of R, Python, and similar “high-productivity” environments know that native control flow constructs (for-loops, etc) in those languages kill performance unless they can be expressed in “vectorized” form. One big attraction of Julia to me is that it claims to fix this inconvenience. Let’s have a look.\nPreview  Julia, Python, Java, and C++ are compared for implementing the same iterative algorithm (knapsack solver) . The implementation does virtually no memory allocation, so what’s being tested is the speed of looping and array access. Julia is fast (although not quite as fast as C++ or Java). Python, however, comes out looking horribly slow by comparison.   Benchmark problem For a simple yet realistic test of performance let’s code a solution to the 0/1 knapsack problem. I am sure you’ve heard of it – it is a classic discrete optimization problem in its own right and shows up as a building block within many optimization algorithms.\nAs a reminder, the problem is to pack a knapsack of finite weight capacity with a chosen set of items of varying value so as to maximize the total packed value:\n\\[ \\begin{equation*} \\begin{aligned} \u0026amp; \\underset{x}{\\text{maximize}} \u0026amp; \u0026amp; V = \\sum_{i=1}^n v_i x_i \\\\ \u0026amp; \\text{subject to} \u0026amp; \u0026amp; \\sum_{i=1}^n w_i x_i \\leq W \\\\ \u0026amp; \u0026amp; \u0026amp; x_i \\in \\{0,1\\} \\text{ for all } i \\text{ in } \\{1,\\dots,n\\} \\end{aligned} \\end{equation*} \\] We have \\(n\\) items of integral1 weights \\(w_i \u0026gt; 0\\) and value \\(v_i\\). \\(W\\) is the knapsack weight capacity. Each item is either chosen or not, hence the “0/1” in the name.\nSince all \\(x_i\\) are restricted to be binary (boolean), this is an integer linear problem with a search space size of \\(2^n\\). It can be given to an MILP solver. But because of a simple nested structure the problem also has a straightforward dynamic programming (DP) solution that I can code in a few lines.\n Dynamic programming algorithm Assume the problem has been solved for all knapsack capacities up to some \\(w\\) while making use of only a subset of items \\(1, \\dots, j\\), and let \\(V(w, j)\\) be the solution, i.e. the maximum achievable knapsack value. Now consider all smaller subproblems without item \\(j\\), \\(V(w\u0026#39;, j-1)\\) for all possible \\(w\u0026#39;\\). \\(V(w, j)\\) and \\(V(w\u0026#39;, j-1)\\) are connected with a single “move” of looking at item \\(j\\) and deciding to either include it in the optimal selection for knapsack \\(V(w, j)\\) or not:\n if including item \\(j\\) is a move that’s feasible (\\(w_j \\leq w\\)) then \\(V(w, j)\\) is the best of \\(v_j + V(w\u0026#39;, j - 1)\\) and \\(V(w\u0026#39;, j - 1)\\) depending on whether the move is “optimal” (improves \\(V\\)) or not; in the former case \\(w\u0026#39; = w - w_j\\) and in the latter \\(w\u0026#39; = w\\); if including item \\(j\\) is not feasible (\\(w_j \u0026gt; w\\)) then \\(V(w, j) = V(w\u0026#39;, j - 1)\\) and \\(w\u0026#39; = w\\); \\(V(w, 1)\\) is 0 or \\(v_1\\) depending on whether the first item fits within capacity \\(w\\).  In other words, knapsack subproblems have a recurrent relationship for \\(j \u0026gt; 1\\)\n\\[ V(w, j) = \\left\\{ \\begin{array}{@{}ll@{}} V(w , j - 1) \u0026amp; \\text{if}\\ w \\lt w_j, \\\\ \\max \\big\\{v_j + V(w - w_j, j - 1),V(w , j - 1)\\big\\} , \u0026amp; \\text{otherwise} \\\\ \\end{array} \\right. \\] together with a boundary condition for \\(j = 1\\) \\[ V(w, 1) = \\left\\{ \\begin{array}{@{}ll@{}} 0 \u0026amp; \\text{if}\\ w \\lt w_1, \\\\ v_1, \u0026amp; \\text{otherwise} \\\\ \\end{array} \\right. \\]\n(The above could be stated more compactly if \\(j\\) started at 0 and \\(V(w,0)\\) were defined as 0.)\nTo capture inputs into a problem instance, I will use an array of Julia structs. Although I could get away with a list or a tuple, I think a struct makes for more readable example code:\nstruct Item value ::Int64; weight ::Int64; end If \\(V(w, j)\\) is represented as a matrix (another first-class citizen in Julia), a non-recursive implementation would be to sweep the space of \\(w\\) and \\(j\\) going from smaller to larger item sets:\nfunction opt_value(W ::Int64, items ::Array{Item}) ::Int64 n = length(items) # V[w,j] stores opt value achievable with capacity \u0026#39;w\u0026#39; and using items \u0026#39;1..j\u0026#39;: V = Array{Int64}(undef, W, n) # W×n matrix with uninitialized storage # initialize first column v[:, 1] to trivial single-item solutions: V[:, 1] .= 0 V[items[1].weight:end, 1] .= items[1].value # do a pass through remaining columns: for j in 2 : n itemⱼ = items[j] for w in 1 : W V_without_itemⱼ = V[w, j - 1] V_allow_itemⱼ = (w \u0026lt; itemⱼ.weight ? V_without_itemⱼ : (itemⱼ.value + (w ≠ itemⱼ.weight ? V[w - itemⱼ.weight, j - 1] : 0))) V[w, j] = max(V_allow_itemⱼ, V_without_itemⱼ) end end return V[W, n] end That loop is almost a straightforward translation of my recurrence, although the body needs some extra edge condition checks. Note the familiar ?: syntax for ternary operator and some comforting exploitation of Julia’s support for Unicode math symbols.\nThis may not be the best bit of Julia code you’ll ever see, but I’ve literally just learned enough syntax for my first experiment here. One performance-related concession to Julia has already been included above by arranging to traverse \\(V\\) in column-major order. Yes, Julia opts for R/MATLAB/Fortran design choice here and that is not under end user control, as far as I can tell at this point. Right now, it does feel like R and yet awkwardly different from C++, which would be my production choice for this particular problem.\n An obvious improvement Notice also that I cheat a little and do not compute half of the solution, specifically the optimal \\(x_i\\)’s2. This is to keep the experiment simple and focus on iterative performance only. However, since this means I don’t need to capture the optimal solution structure in \\(V\\) matrix, I don’t need to allocate it: it is sufficient to allocate a couple of buffers for columns \\(j\\) and \\(j-1\\) and re-use them as needed:\nfunction opt_value(W ::Int64, items ::Array{Item}) ::Int64 n = length(items) V = zeros(Int64, W) # single column of size W, zero-initialized V_prev = Array{Int64}(undef, W) # single column of size W, uninitialized storage V[items[1].weight:end] .= items[1].value for j in 2 : n V, V_prev = V_prev, V itemⱼ = items[j] for w in 1 : W V_without_itemⱼ = V_prev[w] V_allow_itemⱼ = (w \u0026lt; itemⱼ.weight ? V_without_itemⱼ : (itemⱼ.value + (w ≠ itemⱼ.weight ? V_prev[w - itemⱼ.weight] : 0))) V[w] = max(V_allow_itemⱼ, V_without_itemⱼ) end end return V[W] end This version will now scale to quite large problem instances.\n Algorithm speed: Julia vs Python vs Java vs C++ To measure performance, I use the @elapsed macro from Julia’s family of @time and friends with randomly constructed problem instances of different scale. Because Julia is JIT-based I need to be careful and do a few timing repeats after burning the very first measurement.\nActually, I’ll use the median of 5 repeats which is even more robust:\nfunction run(repeats = 5) @assert repeats \u0026gt; 1 times = zeros(Float64, repeats) seed = 12345 for W in [5_000, 10_000, 20_000, 40_000, 80_000] for repeat in 1 : repeats spec = make_random_data(W, seed += 1) times[repeat] = @elapsed opt_value(spec[1], spec[2]) end sort!(times) println(W, \u0026quot;, \u0026quot;, times[(repeats + 1) ÷ 2]) end end For the promised language shootout, I’ve implemented this same algorithm in three other languages: Python, Java, and C++. I event went as far as make sure that all “ports” used similar array data types and even the exact same random number generator for building the exact same random problem instances. To maintain consistency with statically typed languages (Java, C++), I ensure that value types used by the dynamic versions are 64-bit integers as much as possible – this required some minor contortions in Python.\nHere’s the C++ version of opt_value() (you can get all four language versions from this github repo, there is a single source file per language that’s trivial to compile and run):\nint64_t opt_value (int64_t const W, std::vector\u0026lt;item\u0026gt; const \u0026amp; items) { auto const n = items.size (); std::unique_ptr\u0026lt;int64_t []\u0026gt; const v_data { std::make_unique\u0026lt;int64_t []\u0026gt; (W) }; // \u0026quot;zeros\u0026quot; std::unique_ptr\u0026lt;int64_t []\u0026gt; const v_prev_data { std::make_unique\u0026lt;int64_t []\u0026gt; (W) }; // \u0026quot;zeros\u0026quot; int64_t * V { v_data.get () }; int64_t * V_prev { v_prev_data.get () }; for (int64_t w = items[0].weight; w \u0026lt;= W; ++ w) V[w - 1] = items[0].value; for (std::size_t j = 1; j \u0026lt; n; ++ j) { std::swap (V, V_prev); item const \u0026amp; item { items [j] }; for (int64_t w = 1; w \u0026lt;= W; ++ w) { auto const V_without_item_j = V_prev[w - 1]; auto const V_allow_item_j = (w \u0026lt; item.weight ? V_without_item_j : (item.value + (w != item.weight ? V_prev[w - 1 - item.weight] : 0))); V[w - 1] = std::max(V_allow_item_j, V_without_item_j); } } return V[W - 1]; } I’ve tried to keep the implementation consistent and idiomatic within each language. (It helps that my algorithm is basically a couple of nested loops without memory allocation, some arithmetic, and not much else.) All these implementations could in principle be tuned further using language-specific techniques, but that’s not my goal here.\nHere is a snippet of calculation latency data for \\(W=80000\\), captured on the exact same CPU:\n  lang  W  time (sec)      julia  80000  0.1135    python  80000  28.2094    java  80000  0.0781    c++  80000  0.0710     Hmm. Perhaps you begin to suspect that Python is not going to win this. Here is a log-log plot of all data, for all \\(W\\)’s:\n Figure 1: Calculation time as a function of knapsack problem size. (Note that both axes use log scale.)  Julia is about 50% slower than either Java or C++. But it is Python that is the real laggard in the group: slower by more than 100x across the entire range of tested problem sizes. Ouch!\nGoing back to the matrix version of the algorithm, you can see how the matrix is accessed predictably over \\(j\\) columns but somewhat randomly (in a data-depedent fashion) over \\(w\\) rows. There doesn’t seem to be a way to express the algorithm in linear algebra operations. This difficulty is retained in the optimized two-column-buffer version. The algorithm is short and simple but there just doesn’t seem to be a way to vectorize it so that it would be fast, say, in numpy. Massive underperformance of the Python version is the cost I pay for slow interpretation of Python bytecode.\nAs for Julia, so far so good. I might just get used to the “no need to vectorize code to make it fast” lifestyle.\n  Restricting weights to be integral is not crucial to my test here but could make the problem statement acceptable to more solver types.↩\n Some might argue that \\(x_i\\)’s are in fact more than half of the solution. Ok, so I cheat a lot.↩\n   ","date":1568246400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568246400,"objectID":"b8c7a1dfd86e76bae738e1a867b98081","permalink":"/tutorials/study_julia_with_me/knapsack_benchmark/","publishdate":"2019-09-12T00:00:00Z","relpermalink":"/tutorials/study_julia_with_me/knapsack_benchmark/","section":"tutorials","summary":"Every once in a while, you need to try an algorithm that’s “custom enough” that it must be coded directly in your “research language”. Perhaps the existing “high-performance” libs don’t support your desired variant or it’s too much setup work switching to another language just to prototype a quick one-off idea. This an instance of the “two language problem” that’s been the reality of technical computing for decades.\nUsers of R, Python, and similar “high-productivity” environments know that native control flow constructs (for-loops, etc) in those languages kill performance unless they can be expressed in “vectorized” form.","tags":null,"title":"How do you say \"0/1 knapsack\" in four languages?","type":"docs"}]